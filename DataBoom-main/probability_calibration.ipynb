{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "#\n",
    "# Prepare the data\n",
    "#\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "# get the labels\n",
    "y = train.target.values\n",
    "train.drop(['id', 'target'], inplace=True, axis=1)\n",
    "\n",
    "x = train.values\n",
    "\n",
    "#\n",
    "# Create training and validation sets\n",
    "#\n",
    "x, x_test, y, y_test = train_test_split(x, y, test_size=0.6, random_state=13, stratify=y)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42, stratify=y_test)\n",
    "\n",
    "\n",
    "#\n",
    "# Create the LightGBM data containers\n",
    "#\n",
    "categorical_features = [c for c, col in enumerate(train.columns) if 'cat' in col]\n",
    "train_data = lightgbm.Dataset(x, label=y, categorical_feature=categorical_features)\n",
    "test_data = lightgbm.Dataset(x_test, label=y_test)\n",
    "valid_data = lightgbm.Dataset(x_valid, label=y_valid)\n",
    "\n",
    "\n",
    "#\n",
    "# Train the model\n",
    "#\n",
    "\n",
    "parameters = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "model_xgb = lightgbm.train(parameters,\n",
    "                       train_data,\n",
    "                       valid_sets=valid_data,\n",
    "                       num_boost_round=5000,\n",
    "                       early_stopping_rounds=100,verbose_eval = 100\n",
    "                          )\n",
    "#\n",
    "# Create a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    return np.log(x/(1-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def give_ece_data(preds,bins,y_valid):\n",
    "    sorted_ind = np.argsort(preds)\n",
    "    predicted_bins = [[] for _ in range(bins)]\n",
    "    actual_counters = [[] for _ in range(bins)]\n",
    "    counters = [[] for _ in range(bins)]\n",
    "    index = 0\n",
    "    length_array = len(sorted_ind)\n",
    "    step = 1.*length_array//bins\n",
    "    for _ in range(bins):\n",
    "        current = int(step*index)\n",
    "        next_ = int(step*(index+1))\n",
    "        predicted_bins[index] = np.mean(preds[sorted_ind[current:next_]])\n",
    "        actual_counters[index] = np.mean(y_valid[sorted_ind[current:next_]])\n",
    "        counters[index] = len(y_valid[sorted_ind[current:next_]])\n",
    "        index += 1\n",
    "    return predicted_bins,actual_counters,counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "preds = model_xgb.predict(x_valid)\n",
    "bins = 1000\n",
    "predicted_bins,actual_counters,counters = give_ece_data(preds,bins,y_valid)\n",
    "\n",
    "plt.scatter(predicted_bins,actual_counters)\n",
    "ece = 0\n",
    "for i in range(bins):\n",
    "    ece +=  counters[i]*np.abs((predicted_bins[i] - actual_counters[i]))\n",
    "ece /= len(preds)\n",
    "print(ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "preds = model_xgb.predict(x_test)\n",
    "bins = 1000\n",
    "\n",
    "predicted_bins,actual_counters,counters = give_ece_data(preds,bins,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(predicted_bins,actual_counters)\n",
    "ece = 0\n",
    "for i in range(bins):\n",
    "    ece +=  counters[i]*np.abs((predicted_bins[i] - actual_counters[i]))\n",
    "ece /= len(preds)\n",
    "print(ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(min_samples_leaf=1700,max_depth=5)\n",
    "tree_model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "TREE = tree_model.tree_\n",
    "indexes = TREE.apply(x_valid.astype(np.float32))\n",
    "predicts_from_xgboost = model_xgb.predict(x_valid)\n",
    "predicts_from_xgboost = predicts_from_xgboost.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "log_reg_dict = {}\n",
    "nodes = np.unique(indexes)\n",
    "model = LogisticRegression()\n",
    "for node in tqdm_notebook(nodes):\n",
    "    model.fit(transform(predicts_from_xgboost[indexes==node]),y_valid[indexes==node])\n",
    "    log_reg_dict[node] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "indexes_test = TREE.apply(x_test.astype(np.float32))\n",
    "predicts_from_xgboost_test = model_xgb.predict(x_test)\n",
    "predicts_from_xgboost_test = predicts_from_xgboost_test.reshape((-1,1))\n",
    "predicts_calibrated = np.zeros_like(predicts_from_xgboost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for node in tqdm_notebook(log_reg_dict.keys()):\n",
    "    predicts_calibrated[indexes_test==node] = log_reg_dict[node].\\\n",
    "        predict_proba(transform(predicts_from_xgboost_test[indexes_test==node]))[:,1].reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bins = 10\n",
    "predicted_bins,actual_counters,counters = give_ece_data(predicts_calibrated.reshape((-1)),bins,y_test)\n",
    "\n",
    "plt.scatter(predicted_bins,actual_counters)\n",
    "\n",
    "ece = 0\n",
    "for i in range(bins):\n",
    "    ece +=  counters[i]*np.abs((predicted_bins[i] - actual_counters[i]))\n",
    "ece /= len(preds)\n",
    "print(ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bins = 100\n",
    "predicted_bins,actual_counters,counters = give_ece_data(predicts_calibrated.reshape((-1)),bins,y_test)\n",
    "\n",
    "plt.scatter(predicted_bins,actual_counters)\n",
    "\n",
    "ece = 0\n",
    "for i in range(bins):\n",
    "    ece +=  counters[i]*np.abs((predicted_bins[i] - actual_counters[i]))\n",
    "ece /= len(preds)\n",
    "print(ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bins = 1000\n",
    "\n",
    "predicted_bins,actual_counters,counters = give_ece_data(predicts_calibrated.reshape((-1)),bins,y_test)\n",
    "\n",
    "plt.scatter(predicted_bins,actual_counters)\n",
    "\n",
    "ece = 0\n",
    "for i in range(bins):\n",
    "    ece +=  counters[i]*np.abs((predicted_bins[i] - actual_counters[i]))\n",
    "ece /= len(preds)\n",
    "print(ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bins = 20\n",
    "\n",
    "predicted_bins,actual_counters,counters = give_ece_data(predicts_calibrated.reshape((-1)),bins,y_test)\n",
    "\n",
    "plt.scatter(predicted_bins,actual_counters)\n",
    "\n",
    "ece = 0\n",
    "for i in range(bins):\n",
    "    ece +=  counters[i]*np.abs((predicted_bins[i] - actual_counters[i]))\n",
    "ece /= len(preds)\n",
    "print(ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_test,predicts_calibrated))\n",
    "print(roc_auc_score(y_test,predicts_from_xgboost_test))\n",
    "assert np.sum(predicts_from_xgboost_test) - np.sum(preds) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(min_samples_leaf=1000,max_depth=5)\n",
    "tree_model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "TREE = tree_model.tree_\n",
    "indexes = TREE.apply(x.astype(np.float32))\n",
    "predicts_from_xgboost = model_xgb.predict(x)\n",
    "predicts_from_xgboost = predicts_from_xgboost.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "log_reg_dict = {}\n",
    "nodes = np.unique(indexes)\n",
    "for node in tqdm_notebook(nodes):\n",
    "    model = LogisticRegression()\n",
    "#     model.fit(predicts_from_xgboost[indexes==node],y[indexes==node])\n",
    "    model.fit(transform(predicts_from_xgboost[indexes==node]),y[indexes==node])\n",
    "\n",
    "    log_reg_dict[node] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "indexes_test = TREE.apply(x_test.astype(np.float32))\n",
    "predicts_from_xgboost_test = model_xgb.predict(x_test)\n",
    "predicts_from_xgboost_test = predicts_from_xgboost_test.reshape((-1,1))\n",
    "predicts_calibrated = np.zeros_like(predicts_from_xgboost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for node in tqdm_notebook(log_reg_dict.keys()):\n",
    "#     predicts_calibrated[indexes_valid==node] = \\\n",
    "#     log_reg_dict[node].predict_proba(predicts_from_xgboost_valid[indexes_valid==node])[:,1].reshape((-1,1))\n",
    "    predicts_calibrated[indexes_test==node] = log_reg_dict[node].\\\n",
    "        predict_proba(transform(predicts_from_xgboost_test[indexes_test==node]))[:,1].reshape((-1,1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bins = 1000\n",
    "\n",
    "predicted_bins,actual_counters,counters = give_ece_data(predicts_calibrated.reshape((-1)),bins,y_test)\n",
    "\n",
    "plt.scatter(predicted_bins,actual_counters)\n",
    "\n",
    "ece = 0\n",
    "for i in range(bins):\n",
    "    ece +=  counters[i]*np.abs((predicted_bins[i] - actual_counters[i]))\n",
    "ece /= len(preds)\n",
    "print(ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_test,predicts_calibrated))\n",
    "print(roc_auc_score(y_test,predicts_from_xgboost_test))\n",
    "assert np.sum(predicts_from_xgboost_test) - np.sum(preds) == 0"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
