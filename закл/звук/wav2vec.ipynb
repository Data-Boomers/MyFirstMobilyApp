{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8130934,"sourceType":"datasetVersion","datasetId":4555568}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers -q","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:14:05.110226Z","iopub.execute_input":"2024-11-10T21:14:05.111002Z","iopub.status.idle":"2024-11-10T21:14:18.301828Z","shell.execute_reply.started":"2024-11-10T21:14:05.110961Z","shell.execute_reply":"2024-11-10T21:14:18.300673Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport librosa\nimport gc\nimport ast\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport torchaudio\nimport sys\nimport datasets\nfrom datasets import load_dataset,load_metric\nfrom transformers import AutoFeatureExtractor\nfrom transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-10T21:14:18.303860Z","iopub.execute_input":"2024-11-10T21:14:18.304171Z","iopub.status.idle":"2024-11-10T21:14:38.214614Z","shell.execute_reply.started":"2024-11-10T21:14:18.304143Z","shell.execute_reply":"2024-11-10T21:14:38.213782Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2024-11-10 21:14:30.060730: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-11-10 21:14:30.060830: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-11-10 21:14:30.192928: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"model_checkpoint = \"facebook/wav2vec2-base\"\nbatch_size = 32\nmetric = load_metric(\"accuracy\")\ndataset = load_dataset(\"audiofolder\", data_dir=\"/kaggle/input/the-fake-or-real-dataset/for-norm/for-norm\")","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:21:32.364569Z","iopub.execute_input":"2024-11-10T21:21:32.365267Z","iopub.status.idle":"2024-11-10T21:27:29.639876Z","shell.execute_reply.started":"2024-11-10T21:21:32.365232Z","shell.execute_reply":"2024-11-10T21:27:29.639011Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1450897772.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric(\"accuracy\")\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8dc4ae595b2443782e6bd4d29ae0c6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/53868 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5808bdec4b484d1da00bfec54e4df253"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/10798 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27628a6aad5d4f808d1190fe599d2733"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/4634 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2e00856746642f3b91ad74bff5dff61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8c078c0504947b7810bb327da3ea774"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3068198f7d2b404797b41b8ef0ef0ab6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eab12a0ff41a48829af1bb5ce722bfb6"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"labels = dataset[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = str(i)\n    id2label[str(i)] = label","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:29:00.832018Z","iopub.execute_input":"2024-11-10T21:29:00.832403Z","iopub.status.idle":"2024-11-10T21:29:00.838034Z","shell.execute_reply.started":"2024-11-10T21:29:00.832373Z","shell.execute_reply":"2024-11-10T21:29:00.837031Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"device = 'cuda'\nfeature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint, device=device)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:30:53.508946Z","iopub.execute_input":"2024-11-10T21:30:53.509965Z","iopub.status.idle":"2024-11-10T21:30:53.687506Z","shell.execute_reply.started":"2024-11-10T21:30:53.509928Z","shell.execute_reply":"2024-11-10T21:30:53.686521Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"max_duration = 5.0  # seconds","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:30:59.838284Z","iopub.execute_input":"2024-11-10T21:30:59.838650Z","iopub.status.idle":"2024-11-10T21:30:59.842872Z","shell.execute_reply.started":"2024-11-10T21:30:59.838620Z","shell.execute_reply":"2024-11-10T21:30:59.842015Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def preprocess_function(examples):\n    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n    inputs = feature_extractor(\n        audio_arrays, \n        sampling_rate=feature_extractor.sampling_rate, \n        max_length=int(feature_extractor.sampling_rate * max_duration), \n        truncation=True, \n    )\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:32:39.586744Z","iopub.execute_input":"2024-11-10T21:32:39.587447Z","iopub.status.idle":"2024-11-10T21:32:39.594886Z","shell.execute_reply.started":"2024-11-10T21:32:39.587414Z","shell.execute_reply":"2024-11-10T21:32:39.594041Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"encoded_dataset = dataset.map(preprocess_function, remove_columns=[\"audio\"], batched=True)\nencoded_dataset","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:32:40.253725Z","iopub.execute_input":"2024-11-10T21:32:40.254425Z","iopub.status.idle":"2024-11-10T21:42:13.820670Z","shell.execute_reply.started":"2024-11-10T21:32:40.254394Z","shell.execute_reply":"2024-11-10T21:42:13.819698Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/53868 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65c2d7b013464253a174ec89d136a390"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Mean of empty slice.\n  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in divide\n  ret = ret.dtype.type(ret / rcount)\n/opt/conda/lib/python3.10/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Degrees of freedom <= 0 for slice\n  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n  arrmean = um.true_divide(arrmean, div, out=arrmean,\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in divide\n  ret = ret.dtype.type(ret / rcount)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10798 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86cc9323f8704e989ae995f17b3cef77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4634 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8e3199bdba34de1b71b971f8f120c08"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'input_values'],\n        num_rows: 53868\n    })\n    validation: Dataset({\n        features: ['label', 'input_values'],\n        num_rows: 10798\n    })\n    test: Dataset({\n        features: ['label', 'input_values'],\n        num_rows: 4634\n    })\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"num_labels = len(id2label)\nmodel = AutoModelForAudioClassification.from_pretrained(\n    model_checkpoint, \n    num_labels=num_labels,\n    label2id=label2id,\n    id2label=id2label,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:46:08.893532Z","iopub.execute_input":"2024-11-10T21:46:08.894185Z","iopub.status.idle":"2024-11-10T21:46:11.629431Z","shell.execute_reply.started":"2024-11-10T21:46:08.894152Z","shell.execute_reply":"2024-11-10T21:46:11.628659Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/380M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2be129765744ba1a64478633bf98626"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"model_name = model_checkpoint.split(\"/\")[-1]\n\n\nargs = TrainingArguments(\n    f\"{model_name}-finetuned-ks\",\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=batch_size,\n    gradient_accumulation_steps=4,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=5,\n    warmup_ratio=0.1,\n    logging_steps=10,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    \n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n    predictions = np.argmax(eval_pred.predictions, axis=1)\n    return metric.compute(predictions=predictions, references=eval_pred.label_ids)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=encoded_dataset[\"train\"],\n    eval_dataset=encoded_dataset[\"validation\"],\n    tokenizer=feature_extractor,\n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:39:11.463247Z","iopub.execute_input":"2024-04-16T22:39:11.464121Z","iopub.status.idle":"2024-04-17T05:00:35.133777Z","shell.execute_reply.started":"2024-04-16T22:39:11.464088Z","shell.execute_reply":"2024-04-17T05:00:35.132904Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T05:01:42.907612Z","iopub.execute_input":"2024-04-17T05:01:42.908426Z","iopub.status.idle":"2024-04-17T05:08:46.588743Z","shell.execute_reply.started":"2024-04-17T05:01:42.908393Z","shell.execute_reply":"2024-04-17T05:08:46.586818Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T05:09:15.872973Z","iopub.execute_input":"2024-04-17T05:09:15.873438Z","iopub.status.idle":"2024-04-17T05:09:30.43091Z","shell.execute_reply.started":"2024-04-17T05:09:15.873405Z","shell.execute_reply":"2024-04-17T05:09:30.430059Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.predict(encoded_dataset[\"test\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T05:35:14.488798Z","iopub.execute_input":"2024-04-17T05:35:14.489237Z","iopub.status.idle":"2024-04-17T05:37:40.322204Z","shell.execute_reply.started":"2024-04-17T05:35:14.4892Z","shell.execute_reply":"2024-04-17T05:37:40.321387Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}