{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOAyuMuYYMgV575OP4zz1bQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%pip install autodistill-grounded-sam autodistill-yolov8 roboflow"],"metadata":{"id":"CudZ9vDETLFs"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"id":"u6SuG6WFGYhO","executionInfo":{"status":"ok","timestamp":1731012254252,"user_tz":-180,"elapsed":278,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["from autodistill_grounded_sam import GroundedSAM\n","from autodistill.detection import CaptionOntology\n","from autodistill.utils import plot\n","import cv2\n","\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# define an ontology to map class names to our GroundedSAM prompt\n","# the ontology dictionary has the format {caption: class}\n","# where caption is the prompt sent to the base model, and class is the label that will\n","# be saved for that caption in the generated annotations\n","# then, load the model"]},{"cell_type":"code","source":["np.random.seed(3)\n","\n","def show_mask(mask, ax, random_color=False, borders = True):\n","    if random_color:\n","        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n","    else:\n","        color = np.array([30/255, 144/255, 255/255, 0.6])\n","    h, w = mask.shape[-2:]\n","    mask = mask.astype(np.uint8)\n","    mask_image =  mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n","    if borders:\n","        import cv2\n","        contours, _ = cv2.findContours(mask,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","        # Try to smooth contours\n","        contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n","        mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2)\n","    ax.imshow(mask_image)\n","\n","def show_points(coords, labels, ax, marker_size=375):\n","    pos_points = coords[labels==1]\n","    neg_points = coords[labels==0]\n","    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n","    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n","\n","def show_box(box, ax):\n","    x0, y0 = box[0], box[1]\n","    w, h = box[2] - box[0], box[3] - box[1]\n","    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))\n","\n","def show_masks(image, masks, scores, point_coords=None, box_coords=None, input_labels=None, borders=True):\n","    for i, (mask, score) in enumerate(zip(masks, scores)):\n","        plt.figure(figsize=(10, 10))\n","        plt.imshow(image)\n","        show_mask(mask, plt.gca(), borders=borders)\n","        if point_coords is not None:\n","            assert input_labels is not None\n","            show_points(point_coords, input_labels, plt.gca())\n","        if box_coords is not None:\n","            # boxes\n","            show_box(box_coords, plt.gca())\n","        if len(scores) > 1:\n","            plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n","        plt.axis('off')\n","        plt.show()"],"metadata":{"id":"iMdb7WheUxX2","executionInfo":{"status":"ok","timestamp":1731011558023,"user_tz":-180,"elapsed":270,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["classes = {\n","    \"man\": \"man\",\n","    \"id\": \"id\",\n","}\n","\n","base_model = GroundedSAM(\n","    ontology=CaptionOntology(\n","        classes\n","    )\n",")"],"metadata":{"id":"BQnIm-8fTooe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#predict on single image\n","results = base_model.predict(\"logistics.jpeg\")"],"metadata":{"id":"QV5j997qVX12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#one mask - one photo\n","if plot := False:\n","  show_masks(Image.open(\"/content/паспорт+лицо.jpg\"), masks=results.mask, scores=results.confidence)"],"metadata":{"id":"4WfN3-2jVFgv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#all masks on same photo\n","if plot := False:\n","  plot(\n","      image=cv2.imread(\"/content/паспорт+лицо.jpg\"),\n","      classes=base_model.ontology.classes(),\n","      detections=results\n","  )"],"metadata":{"id":"CwQZzpcfUTZ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def inference_seg_on_fold(base_model, fold_path):\n","  preds = base_model.label(fold_path, extension=\".jpg\")\n","  res_dict = {}\n","  for img_name, detections in tqdm(preds.annotations.items()):\n","    res_dict[img_name] = {\n","        'masks' : detections.mask,\n","        'conf' : detections.confidence,\n","        'class_ids' : detections.class_id\n","    }\n","  return res_dict"],"metadata":{"id":"pPa9eH1MV2Je","executionInfo":{"status":"ok","timestamp":1731012340629,"user_tz":-180,"elapsed":475,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["resutls = inference_seg_on_fold(\n","    base_model=base_model,\n","    fold_path='/content/context_images'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XzR2myq-V8bI","executionInfo":{"status":"ok","timestamp":1731012343579,"user_tz":-180,"elapsed":2955,"user":{"displayName":"ISY640","userId":"14578547707035782428"}},"outputId":"6c817dbe-4257-4ec4-9447-d49725f67e01"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["Labeling /content/context_images/паспорт+лицо.jpg:   0%|          | 0/1 [00:00<?, ?it/s]The `device` argument is deprecated and will be removed in v5 of Transformers.\n","torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","None of the inputs have requires_grad=True. Gradients will be None\n","`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","Labeling /content/context_images/паспорт+лицо.jpg: 100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n","Passing a `Dict[str, np.ndarray]` into `DetectionDataset` is deprecated and will be removed in `supervision-0.26.0`. Use a list of paths `List[str]` instead.\n"]},{"output_type":"stream","name":"stdout","text":["Found /content/context_images_labeled/valid/images/паспорт+лицо.jpg as already present, not moving anything to /content/context_images_labeled/valid/images\n","Found /content/context_images_labeled/valid/labels/паспорт+лицо.txt as already present, not moving anything to /content/context_images_labeled/valid/labels\n","Labeled dataset created - ready for distillation.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 1301.37it/s]\n"]}]},{"cell_type":"code","source":["resutls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rq_P_pmTXrCI","executionInfo":{"status":"ok","timestamp":1731012347555,"user_tz":-180,"elapsed":4,"user":{"displayName":"ISY640","userId":"14578547707035782428"}},"outputId":"af7a56b2-cb82-4050-83f5-5253cc5be966"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'паспорт+лицо.jpg': {'masks': array([[[False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          ...,\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False]],\n","  \n","         [[False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          ...,\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False]],\n","  \n","         [[False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          ...,\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False],\n","          [False, False, False, ..., False, False, False]]]),\n","  'conf': array([0.76805294, 0.4873882 , 0.75970995], dtype=float32),\n","  'class_ids': array([0, 0, 1])}}"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":[],"metadata":{"id":"l91oJv-xXxm8"},"execution_count":null,"outputs":[]}]}