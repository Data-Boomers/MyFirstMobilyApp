{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08410fd6-244a-4cb6-9246-c32cca121cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install shap imblearn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf1f7323-150a-441e-b500-febe616b4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other tools\n",
    "import pickle\n",
    "import random\n",
    "import torch # (нужен для проверки использования GPU)\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from typing_extensions import Literal, Any, Callable, List\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# Train\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visual\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "# Preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Model\n",
    "import catboost\n",
    "import optuna\n",
    "\n",
    "from utils import find_cat_features, set_seed_no_torch, reduce_mem_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86414d01-0cd7-4b5f-855f-1928f4f28396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_with_chunks(path, chunksize, sample_rate, sep=','):\n",
    "\n",
    "    chunks = pd.read_csv(path, chunksize=chunksize, sep=sep)\n",
    "\n",
    "    chunks_dfs = []\n",
    "\n",
    "    for chunk in tqdm(chunks):\n",
    "        chunks_dfs.append(chunk.sample(frac=sample_rate))\n",
    "\n",
    "    return pd.concat(chunks_dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3315e6cf-943a-4c3a-9459-21ca5272779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_with_chunks(\"../shared/Image-Text-Matching/train_df.tsv\", 10e3, 0.01, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a126fd67-1f9c-4ce4-9cab-6f4466d0e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBoostWorker:\n",
    "  def __init__(\n",
    "      self,\n",
    "      task: Literal['reg', 'class'] = \"reg\",\n",
    "      seed: int = 1,\n",
    "      device: Literal['CPU', 'GPU'] =\"CPU\"\n",
    "  ) -> None:\n",
    "      pass\n",
    "\n",
    "      \"\"\"\n",
    "        Column name:  | Default value:      | Column description:\n",
    "                      |                     |\n",
    "        task          | default: 'reg'      | whether this catboost will solve regression('reg') on classification('class') task\n",
    "        seed          | default: 1          | random state to make result reproducable\n",
    "        device        | default: 'CPU'      | device to compute ('CPU'/'GPU')\n",
    "\n",
    "      \"\"\"\n",
    "\n",
    "      # Init-params\n",
    "      self.seed = seed\n",
    "      self.device = device\n",
    "      self.task = task\n",
    "\n",
    "\n",
    "      # Default splits data\n",
    "      self.train_data = None\n",
    "      self.val_data = None\n",
    "      self.test_data = None\n",
    "\n",
    "\n",
    "      # CV setting\n",
    "      self.num_folds = None\n",
    "      self.folds = None\n",
    "      self.cross_val_test_pool = None\n",
    "      self.cross_val_score = None\n",
    "\n",
    "      # Models settings\n",
    "      self.default_model_params = {\n",
    "          \"iterations\" : 100,\n",
    "          \"border_count\" : 254\n",
    "      }\n",
    "      self.default_train_params = {}\n",
    "\n",
    "\n",
    "      # Models\n",
    "\n",
    "      self.model = None\n",
    "      self.folds_models = None\n",
    "\n",
    "\n",
    "  def split_data(\n",
    "      self,\n",
    "      data: Any = None,\n",
    "      target_column: str = \"target\" ,\n",
    "      fold: bool = False,\n",
    "      splits: dict = {\"train\" : 1.0, \"val\" : None, \"test\" : None},\n",
    "      extra_features_columns: dict  = {},\n",
    "      verbose: bool = True\n",
    "  ) -> None:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "      Column name:           | Default value:                                        | Column description:\n",
    "                             |                                                       |\n",
    "      data                   | default: None                                         | dataframe\n",
    "      target_column          | default: 'target'                                     | name of target column\n",
    "      splits                 | default: {\"train\" : 1.0, \"val\" : None, \"test\" : None} | train/val/test splits sizes\n",
    "      extra_features_columns | default: {}                                           | columns with specifical data for catboost like cat_features, embedding_features, text_features\n",
    "      verbose                | default: True                                         | whether show progress of data initalizing or not\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    self.extra_features_columns = extra_features_columns\n",
    "\n",
    "    # getting train/val/test actual sizes\n",
    "    train_size = int(len(data) * splits[\"train\"])\n",
    "\n",
    "    val_size = 0.0\n",
    "    test_size = 0.0\n",
    "    if splits[\"val\"] != None:\n",
    "      val_size = int(len(data) * splits[\"val\"])\n",
    "\n",
    "    if splits[\"test\"] != None:\n",
    "      test_size = int(len(data) * splits[\"test\"])\n",
    "\n",
    "    if verbose:\n",
    "\n",
    "      print(f\"train size: {train_size}, val size: {val_size}, test_size: {test_size}\")\n",
    "\n",
    "    # shake data\n",
    "    np.random.seed(self.seed)\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # saving train/val/test splits to catboost Pools\n",
    "    X = data.drop(columns=[target_column])\n",
    "    Y = data[target_column]\n",
    "\n",
    "    X_train_split = X.iloc[:train_size, :]\n",
    "    Y_train_split = Y.iloc[:train_size]\n",
    "    self.train_data = (X_train_split, Y_train_split)\n",
    "\n",
    "    if val_size != 0.0:\n",
    "\n",
    "      X_val_split = X.iloc[train_size:train_size + val_size, :].reset_index(drop=True)\n",
    "      Y_val_split = Y.iloc[train_size:train_size + val_size].reset_index(drop=True)\n",
    "      self.val_data = (X_val_split, Y_val_split)\n",
    "\n",
    "    if test_size != 0.0:\n",
    "\n",
    "      X_test_split = X.iloc[train_size + val_size:, :].reset_index(drop=True)\n",
    "      Y_test_split = Y.iloc[train_size + val_size:].reset_index(drop=True)\n",
    "      self.test_data = (X_test_split, Y_test_split)\n",
    "\n",
    "    if verbose:\n",
    "\n",
    "      print(\"all pools have been succesfully saved :)\")\n",
    "\n",
    "\n",
    "  def split_folds(\n",
    "      self,\n",
    "      data: Any = None,\n",
    "      target_column: str = \"target\" ,\n",
    "      cv_type: Literal['Classic', 'Stratified'] = \"Classic\",\n",
    "      num_folds: int = 5,\n",
    "      test_size: int = 0.1,\n",
    "      extra_features_columns: dict  = {},\n",
    "      verbose: bool = True,\n",
    "      groups : List = []\n",
    "  ) -> None:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "      Column name:           | Default value:                                        | Column description:\n",
    "                             |                                                       |\n",
    "      data                   | default: None                                         | dataframe\n",
    "      target_column          | default: 'target'                                     | name of target column\n",
    "      num_folds              | default: 5                                            | number of folds for create\n",
    "      cv_type                | default: 'Classic'                                    | type of cross-validation\n",
    "      test_size              | default: 0.1                                          | test-size\n",
    "      verbose                | default: True                                         | whether show progress of data initalizing or not\n",
    "      groups                 | default: []                                           | Groups for StratifiedGroupKFold\n",
    "    \"\"\"\n",
    "\n",
    "    self.extra_features_columns = extra_features_columns\n",
    "\n",
    "    self.num_folds = num_folds\n",
    "\n",
    "    # test split\n",
    "    if test_size != 0.0:\n",
    "\n",
    "      cv_size = int(len(data) * (1 - test_size))\n",
    "\n",
    "      #shake data\n",
    "      np.random.seed(self.seed)\n",
    "      data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "      # saving train/val/test splits to catboost Pools\n",
    "      X = data.drop(columns=[target_column])\n",
    "      Y = data[target_column]\n",
    "\n",
    "      X_cv_data = X.iloc[:cv_size, :]\n",
    "      Y_cv_data = Y.iloc[:cv_size]\n",
    "\n",
    "      X_test_data = X.iloc[cv_size:, :]\n",
    "      Y_test_data = Y.iloc[cv_size:]\n",
    "      self.cross_val_test_data = (X_test_data, Y_test_data)\n",
    "\n",
    "      if verbose:\n",
    "\n",
    "        print(f\"cv_size: {cv_size}, test_size: {len(data) - cv_size}\")\n",
    "\n",
    "    else:\n",
    "\n",
    "      X_cv_data = data.drop(columns=[target_column])\n",
    "      Y_cv_data = data[target_column]\n",
    "\n",
    "    # getting folds\n",
    "    if cv_type == \"Classic\":\n",
    "\n",
    "      kf = sklearn.model_selection.KFold(n_splits=self.num_folds, shuffle=True, random_state=self.seed)\n",
    "\n",
    "    if cv_type == \"Stratified\":\n",
    "\n",
    "      kf = sklearn.model_selection.StratifiedKFold(n_splits=self.num_folds, shuffle=True, random_state=self.seed)\n",
    "\n",
    "    if cv_type == \"StratifiedGroup\":\n",
    "\n",
    "      kf = sklearn.model_selection.StratifiedGroupKFold(n_splits=self.num_folds, shuffle=True, random_state=self.seed)\n",
    "\n",
    "    if cv_type == \"Group\":\n",
    "\n",
    "      kf = sklearn.model_selection.GroupKFold(n_splits=self.num_folds)\n",
    "\n",
    "    if self.task == \"reg\":\n",
    "\n",
    "      Y_to_split_on = pd.qcut(Y_cv_data, self.num_folds, labels = np.arange(self.num_folds))\n",
    "\n",
    "    folds_data = {}\n",
    "\n",
    "    split_args = dict(\n",
    "        X=X_cv_data,\n",
    "        y=(Y_to_split_on if (self.task == \"reg\" and cv_type == \"Stratified\") else Y_cv_data)\n",
    "    )\n",
    "\n",
    "    if cv_type in [\"Group\", \"StratifiedGroup\"]:\n",
    "      split_args[\"groups\"] = groups\n",
    "\n",
    "    for fold, (train_idxs, val_idxs) in enumerate(kf.split(\n",
    "        **split_args\n",
    "    )):\n",
    "\n",
    "      X_train_fold, y_train_fold = X_cv_data.iloc[train_idxs, :], Y_cv_data.iloc[train_idxs]\n",
    "      X_val_fold, y_val_fold = X_cv_data.iloc[val_idxs, ], Y_cv_data.iloc[val_idxs]\n",
    "\n",
    "\n",
    "      X_train_sampled, y_train_sampled = oversample(X_train_fold, y_train_fold)\n",
    "\n",
    "\n",
    "      folds_data[f\"fold_{fold}\"] = ((X_train_sampled, y_train_sampled), (X_val_fold, y_val_fold))\n",
    "\n",
    "      if verbose:\n",
    "\n",
    "        print(f\"fold {fold} saved\")\n",
    "\n",
    "    self.folds = folds_data\n",
    "\n",
    "  def init_model_params(\n",
    "      self,\n",
    "      model_params: dict = {\"iterations\" : 100},\n",
    "      train_params: dict = {}\n",
    "  ) -> None:\n",
    "\n",
    "      \"\"\"\n",
    "        Column name:           | Default value:                                        | Column description:\n",
    "                               |                                                       |\n",
    "        model_params           | default: {\"iterations\" : 100}                         | dict with catboost model initialization params\n",
    "        train_params           | default: {}                                           | dict with catboost model .fit params\n",
    "\n",
    "      \"\"\"\n",
    "\n",
    "      self.default_model_params = model_params\n",
    "      self.default_train_params = train_params\n",
    "\n",
    "\n",
    "  def train_model(self) -> None:\n",
    "\n",
    "    if self.task == \"reg\":\n",
    "\n",
    "      self.model = catboost.CatBoostRegressor(\n",
    "          **self.default_model_params,\n",
    "          random_state=self.seed,\n",
    "          task_type=self.device\n",
    "      )\n",
    "\n",
    "    if self.task == \"class\":\n",
    "\n",
    "      self.model = catboost.CatBoostClassifier(\n",
    "          **self.default_model_params,\n",
    "          random_state=self.seed,\n",
    "          task_type=self.device\n",
    "      )\n",
    "\n",
    "    train_pool = catboost.Pool(data=self.train_data[0], label=self.train_data[1], **self.extra_features_columns)\n",
    "\n",
    "    eval_sets = [train_pool] + ([] if self.val_data == None else [catboost.Pool(data=self.val_data[0], label=self.val_data[1], **self.extra_features_columns)])\n",
    "\n",
    "    self.model.fit(X=train_pool, eval_set=eval_sets, **self.default_train_params)\n",
    "\n",
    "  def train_kfold(\n",
    "      self,\n",
    "      eval_metric: Callable = None,\n",
    "      verbose: bool = True,\n",
    "  ) -> None:\n",
    "\n",
    "    \"\"\"\n",
    "        Column name:           | Default value:                       | Column description:\n",
    "\n",
    "        eval_metric            | default: None                        | metric to evaluate cross-valadation on\n",
    "        verbose                | default: True                        | whether to verbose evaluation process or no\n",
    "    \"\"\"\n",
    "\n",
    "    folds_scores = []\n",
    "    folds_models = []\n",
    "\n",
    "    for fold in range(self.num_folds):\n",
    "      train_fold_data, val_fold_data = self.folds[f\"fold_{fold}\"]\n",
    "\n",
    "      train_fold_pool = catboost.Pool(data=train_fold_data[0], label=train_fold_data[1], **self.extra_features_columns)\n",
    "      val_fold_pool = catboost.Pool(data=val_fold_data[0], label=val_fold_data[1], **self.extra_features_columns)\n",
    "\n",
    "      if self.task == \"reg\":\n",
    "\n",
    "        fold_model = catboost.CatBoostRegressor(\n",
    "            **self.default_model_params,\n",
    "            random_state=self.seed,\n",
    "            task_type=self.device\n",
    "        )\n",
    "\n",
    "      if self.task == \"class\":\n",
    "\n",
    "        fold_model = catboost.CatBoostClassifier(\n",
    "            **self.default_model_params,\n",
    "            random_state=self.seed,\n",
    "            task_type=self.device\n",
    "        )\n",
    "\n",
    "      eval_sets = [train_fold_pool, val_fold_pool]\n",
    "\n",
    "      fold_model.fit(X=train_fold_pool, eval_set=eval_sets, **self.default_train_params)\n",
    "\n",
    "      fold_val_preds = fold_model.predict_proba(val_fold_pool)[:, 1]\n",
    "      fold_val_score = eval_metric(val_fold_pool.get_label(), fold_val_preds)\n",
    "\n",
    "      folds_scores.append(fold_val_score)\n",
    "      folds_models.append(fold_model)\n",
    "\n",
    "      if verbose:\n",
    "        print(f\"FOLD {fold}, VAL SCORE: {fold_val_score}\")\n",
    "\n",
    "    if verbose:\n",
    "      print()\n",
    "      print(f\"mean val score per folds {np.mean(folds_scores)}\")\n",
    "      print(f\"mean val score per folds with regularization {np.mean(folds_scores) - np.std(folds_scores)}\")\n",
    "\n",
    "    self.cross_val_score = np.mean(folds_scores)\n",
    "    self.folds_models = folds_models\n",
    "    self.folds_scores = folds_scores\n",
    "\n",
    "\n",
    "  def inference_model(\n",
    "    self,\n",
    "    return_probs: bool = False,\n",
    "    target_threshold: float = 0.5,\n",
    "    use_kfold_models: bool = False,\n",
    "    test_pool = None,\n",
    "  ):\n",
    "\n",
    "    \"\"\"\n",
    "        Column name:           | Default value:                       | Column description:\n",
    "\n",
    "        return_probs           | default: False                       | whether to return probes or preds\n",
    "        target_threshold       | default: 0.5                         | threshold to make preds from probes\n",
    "        use_kfold_models       | default: False                       | use or not KFold models to eval on test_set\n",
    "        test_pool              | default: None                        | custom test_set to evaluate on\n",
    "    \"\"\"\n",
    "\n",
    "    data_to_inference = None\n",
    "\n",
    "    if test_pool is not None:\n",
    "      data_to_inference = test_pool\n",
    "    elif use_kfold_models:\n",
    "      data_to_inference = catboost.Pool(data=self.cross_val_test_pool[0], label=self.cross_val_test_pool[1], **self.extra_features_columns)\n",
    "    else:\n",
    "      data_to_inference = catboost.Pool(data=self.test_data[0], label=self.test_data[1], **self.extra_features_columns)\n",
    "\n",
    "    if data_to_inference is None:\n",
    "      raise Exception(\"no data to inference\")\n",
    "\n",
    "\n",
    "    if use_kfold_models:\n",
    "\n",
    "      all_models_preds = []\n",
    "      for model in self.folds_models:\n",
    "\n",
    "        model_preds = model.predict_proba(data_to_inference)[:, 1]\n",
    "        all_models_preds.append(model_preds)\n",
    "\n",
    "      if return_probs:\n",
    "        return all_models_preds\n",
    "      else:\n",
    "\n",
    "        probes = np.stack(all_models_preds).mean(axis=0)\n",
    "        final_preds = (probes > target_threshold).astype(int)\n",
    "        return final_preds\n",
    "\n",
    "    else:\n",
    "\n",
    "      probes = self.model.predict_proba(data_to_inference)\n",
    "\n",
    "      if return_probs:\n",
    "\n",
    "        return probes\n",
    "\n",
    "      else:\n",
    "\n",
    "        return (probes[:, 1] > target_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "521c2f4e-fdbd-43a4-8357-f7ecc2fc0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker = CatBoostWorker(\n",
    "    task='class',\n",
    "    seed=1,\n",
    "    device='CPU'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3b59f71-3146-482b-b7ca-4b9ebe2519f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 221, val size: 39, test_size: 0.0\n",
      "all pools have been succesfully saved :)\n"
     ]
    }
   ],
   "source": [
    "df['target'] = 0\n",
    "worker.split_data(\n",
    "  data=df,\n",
    "  target_column=\"target\" ,\n",
    "  fold=False,\n",
    "  splits={\"train\" : 0.85, \"val\" : 0.15, \"test\" : None},\n",
    "  extra_features_columns={},\n",
    "  verbose=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0526b2e4-39f7-4dd6-a036-5dc3b8db77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    iterations=1000,\n",
    "    max_depth=8,\n",
    "    border_count=254,\n",
    "    eval_metric=\"NormalizedGini\",\n",
    "    early_stopping_rounds=50,\n",
    "    use_best_model=True,\n",
    "    auto_class_weights=\"Balanced\",\n",
    "    boosting_type=\"Ordered\",\n",
    "    # learning_rate=0.01,\n",
    "    verbose=25,\n",
    "    colsample_bylevel=0.098,\n",
    "    subsample=0.9,\n",
    "    l2_leaf_reg=9,\n",
    "    min_data_in_leaf=300,\n",
    "    # max_bin=200,\n",
    "    random_strength=1,\n",
    ")\n",
    "\n",
    "worker.init_model_params(\n",
    "    model_params=model_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8295a277-b40d-419c-92eb-1e612326289b",
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "Bad value for num_feature[non_default_doc_idx=0,feature_idx=0]=\"competition_data:8925.png\": Cannot convert 'b'competition_data:8925.png'' to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m_catboost.pyx:2547\u001b[0m, in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:1226\u001b[0m, in \u001b[0;36m_catboost._FloatOrNan\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:1021\u001b[0m, in \u001b[0;36m_catboost._FloatOrNanFromString\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert 'b'competition_data:8925.png'' to float",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m   auc \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mroc_auc_score(label, preds)\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m auc \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#можно использовать как gini, так и просто roc_auc\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# eval_metric=\"normalized_gini\",\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 263\u001b[0m, in \u001b[0;36mCatBoostWorker.train_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m catboost\u001b[38;5;241m.\u001b[39mCatBoostClassifier(\n\u001b[1;32m    258\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_model_params,\n\u001b[1;32m    259\u001b[0m       random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed,\n\u001b[1;32m    260\u001b[0m       task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    261\u001b[0m   )\n\u001b[0;32m--> 263\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m \u001b[43mcatboost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_features_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m eval_sets \u001b[38;5;241m=\u001b[39m [train_pool] \u001b[38;5;241m+\u001b[39m ([] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [catboost\u001b[38;5;241m.\u001b[39mPool(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data[\u001b[38;5;241m0\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_features_columns)])\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mtrain_pool, eval_set\u001b[38;5;241m=\u001b[39meval_sets, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_train_params)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/catboost/core.py:855\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, graph, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr, data_can_be_none)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[1;32m    850\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\n\u001b[1;32m    851\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    852\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    853\u001b[0m             )\n\u001b[0;32m--> 855\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_can_be_none:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/catboost/core.py:1491\u001b[0m, in \u001b[0;36mPool._init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1490\u001b[0m     feature_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_transform_tags(feature_tags, feature_names)\n\u001b[0;32m-> 1491\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m                \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m_catboost.pyx:4339\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4391\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4200\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:3127\u001b[0m, in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2591\u001b[0m, in \u001b[0;36m_catboost.create_num_factor_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2549\u001b[0m, in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: Bad value for num_feature[non_default_doc_idx=0,feature_idx=0]=\"competition_data:8925.png\": Cannot convert 'b'competition_data:8925.png'' to float"
     ]
    }
   ],
   "source": [
    "def normalized_gini(label, preds):\n",
    "  auc = sklearn.metrics.roc_auc_score(label, preds)\n",
    "  return 2 * auc - 1\n",
    "\n",
    "worker.train_model(\n",
    "    #можно использовать как gini, так и просто roc_auc\n",
    "    # eval_metric=\"normalized_gini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dfcc7a-a4ca-4b19-a267-3b73c158a368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
