{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"14EPPjjIG-lb","executionInfo":{"status":"ok","timestamp":1731059572902,"user_tz":-180,"elapsed":12598,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import torch\n","import re\n","import json\n","\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn import functional as F\n","import torch.nn as nn\n","\n","# import maplotlib.pyplot as plt\n","# import seaborn as sns\n","import random\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8QVPyO05G-le","executionInfo":{"status":"ok","timestamp":1731059572903,"user_tz":-180,"elapsed":3,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["# Session settings\n","# pd.set_option('display.max_rows', 15)\n","\n","# plt.rcParams['font.weight'] = 'semibold'\n","# plt.rcParams['figure.figsize'] = 14, 8\n","# plt.rcParams['font.size'] = 18\n","# plt.rcParams['savefig.format'] = 'pdf'\n","\n","# make results reproducable\n","def set_seed(seed=42):\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(SEED)\n","\n","SEED = 69\n","set_seed(SEED)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"t1y7WgkxG-lf","executionInfo":{"status":"ok","timestamp":1731059572903,"user_tz":-180,"elapsed":3,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["with open('/content/NER_data.json', 'r') as f:\n","    lines = f.readlines()\n","    data = []\n","    for line in lines:\n","        js = json.loads(line)\n","        data.append(js)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"1FIzFV2pG-lf","executionInfo":{"status":"ok","timestamp":1731059576275,"user_tz":-180,"elapsed":3375,"user":{"displayName":"ISY640","userId":"14578547707035782428"}},"outputId":"9badf7a8-de16-45fd-c724-20ea4a703955"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               content  \\\n","68   Roshan Sinha\\nApplication Developer - SAP ABAP...   \n","166  Rahul Tayade\\nGlobal Production Support Lead, ...   \n","196  Raktim Podder\\n6+ Exp in banking operations an...   \n","32   Kavitha K\\nSenior System Engineer - Infosys Li...   \n","190  Jatin Arora\\nSDET Automation Engineer, Infosys...   \n","\n","                                            annotation  \n","68   [{'label': ['Skills'], 'points': [{'start': 32...  \n","166  [{'label': ['Skills'], 'points': [{'start': 11...  \n","196  [{'label': ['Skills'], 'points': [{'start': 88...  \n","32   [{'label': ['Graduation Year'], 'points': [{'s...  \n","190  [{'label': ['College Name'], 'points': [{'star...  "],"text/html":["\n","  <div id=\"df-4d5a87c9-1ff3-4f05-a9c5-09bec2b16e7c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>annotation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>68</th>\n","      <td>Roshan Sinha\\nApplication Developer - SAP ABAP...</td>\n","      <td>[{'label': ['Skills'], 'points': [{'start': 32...</td>\n","    </tr>\n","    <tr>\n","      <th>166</th>\n","      <td>Rahul Tayade\\nGlobal Production Support Lead, ...</td>\n","      <td>[{'label': ['Skills'], 'points': [{'start': 11...</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>Raktim Podder\\n6+ Exp in banking operations an...</td>\n","      <td>[{'label': ['Skills'], 'points': [{'start': 88...</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Kavitha K\\nSenior System Engineer - Infosys Li...</td>\n","      <td>[{'label': ['Graduation Year'], 'points': [{'s...</td>\n","    </tr>\n","    <tr>\n","      <th>190</th>\n","      <td>Jatin Arora\\nSDET Automation Engineer, Infosys...</td>\n","      <td>[{'label': ['College Name'], 'points': [{'star...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d5a87c9-1ff3-4f05-a9c5-09bec2b16e7c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4d5a87c9-1ff3-4f05-a9c5-09bec2b16e7c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4d5a87c9-1ff3-4f05-a9c5-09bec2b16e7c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3309e15f-c160-41ba-b11c-669563db7fa2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3309e15f-c160-41ba-b11c-669563db7fa2')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3309e15f-c160-41ba-b11c-669563db7fa2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Rahul Tayade\\nGlobal Production Support Lead, - Infosys Ltd (Technology Lead) - HSBC\\n\\nPune, Maharashtra - Email me on Indeed: indeed.com/r/Rahul-Tayade/ce40c3731cb69763\\n\\n\\u2022 Total 12+ years of IT experience in the analysis, design, development, Testing support,\\nimplementation, CAT support and management of full life cycle applications, project coordination,\\nmanaging development and support projects.\\n\\u2022 More than 7 years of experience on Project Leading support and maintenance project including\\nenhancements of the application.\\n\\u2022 Over 4 years of Project Management experience on support/maintenance projects.\\n\\u2022 Managed multiple applications with team more than 16 members.\\n\\u2022 Involved in PM activities like dealing with customer, identifying new business, get new business,\\naccordingly raising quotes, and get PO approved from customer, track the work and bill customer\\nbased on Resource Utilization, Workforce management, manage project costing by providing\\ncost-effective solutions etc.\\n\\u2022 Involve in SIX Sigma and Lean initiative to remove the unwanted NVA (non-value add) improve\\non costing and performance side\\n\\u2022 Was deputed to client side UK-IPSWICH to deal with client and handle issues, achieve the client\\nconfidence by creating road map for improvement and improving performance and during that\\ntime customer satisfaction rating was increased to 4.9 from 4.4 out of 5.\\n\\u2022 Handled responsibilities as the single point of contact for various projects, transitioning and\\noffshore coordinator.\\n\\u2022 As a ASG Project lead involved in ASG activities like resource management, work allocation,\\nshift management, handling escalations, SLA performance and dashboard reporting, ITES Metric\\nreports, Highlight reports, coordinating and performing deployments, QMG audits, PMR activities\\netc.\\n\\u2022 Practiced ITIL V3 processes during my tenure on application support projects which includes\\nService Transition, Service Operations (Incident management, Change Management, Problem\\nManagement) and Continual Service Improvements\\n\\u2022 Handled effort estimation using Function Point (IFPUG Guidelines), cost estimation and planning\\nvarious projects.\\n\\u2022 Prepared performance improvement plan on activities related to application performance.\\n\\u2022 Managed and Delivered VDC Migrations, Database Migration projects.\\n\\u2022 Capacity planning, work load and work force planning.\\n\\u2022 Interact with the business analysts &amp; application leads to come up with technical designs\\nbased on the functional designs.\\n\\u2022 Worked extensively on Oracle PL/SQL, UNIX, Scripting and have good interpersonal skills.\\n\\u2022 Involved in Service transition and successfully completed all quality gates\\n\\u2022 Documented and Managed DR activities successfully\\n\\u2022 Involved in BCP planning and execution.\\n\\u2022 Team mentoring and help team when needed\\n\\u2022 Involved in escalations and resolve the issue smoothly by involving business stakeholders and\\nteam effectively.\\n\\nWORK EXPERIENCE\\n\\nGlobal Production Support Lead, - Infosys Ltd (Technology Lead)\\n\\nhttps://www.indeed.com/r/Rahul-Tayade/ce40c3731cb69763?isid=rex-download&ikw=download-top&co=IN\\n\\n\\nHSBC -  Pune, Maharashtra -\\n\\nJune 2016 to Present\\n\\nCurrently working in Global Standards IT under the CDD (Customer Due Diligence) program which\\nis responsible for tackling financial crime by implementing new tools to better understand their\\ncustomers.\\n\\nI lead a global 24*7 production support team for a number of Tier 1 KYC (Know Your Client)\\nFCR (Financial Crime Risk) applications and provide hands on application support to a user base\\nacross 35 countries in 42 markets, for HSBC and its subsidiaries First Direct and Marks &amp;\\nSpencer Bank.\\n\\nTasks:\\n\\u2022 Mentoring team on Technical as well as Process front\\n\\u2022 Implementing new processes\\n\\u2022 Implementing a global 24*7 Support Model\\n\\u2022 Supporting the rollout of new customer onboarding tool across 35 countries\\n\\u2022 Supporting weekly release cycles\\n\\nResponsibilities:\\n\\u2022 Offshore Leadership/People Management\\n\\u2022 Service Delivery Management\\n\\u2022 Stakeholder Management\\n\\u2022 Relationship Management\\n\\u2022 Service Recovery Management\\n\\u2022 Production Support\\n\\u2022 Incident Management\\n\\u2022 Problem Management\\n\\u2022 Change Management\\n\\u2022 Release Management &amp; Support during releases\\n\\u2022 Involve in Service Improvement Process for Faster and Smooth delivery\\n\\u2022 Resolving technical issues relating to application from offshore\\n\\u2022 Training &amp; Mentoring new resources for the Projects\\n\\u2022 Documentation and manage Knowledge bank for team reference\\n\\u2022 Documentation and execution of DR activities\\n\\nTechnology Lead\\n\\nHSBC -  Pune, Maharashtra -\\n\\nOctober 2015 to July 2016\\n\\nInvolved in Transition of application\\n\\u2022 Preparation of in Knowledge Transfer plan from HSBC to Infosys,\\n\\u2022 Managing KT schedules and made sure that it working as per plan\\n\\u2022 Managing variance and made sure that portion left should get discussed as per updated plans.\\n\\u2022 Mentoring new team on technical and process front\\n\\u2022 Helping team where laps in KT plan or miscommunications\\n\\u2022 Preparation and scheduling of Reverse KT plans and smooth execution of it\\n\\n\\n\\n\\u2022 Managing stake holders and business and give them confidence for moving support to new\\nteam\\n\\u2022 Made sure that this plan passed from all quality gates in order to start work from new team\\n\\u2022 Documentation of all these Knowledge and Process\\n\\nProject Lead\\n\\nBritish Telecom UK -  Pune, Maharashtra -\\n\\nAugust 2010 to July 2015\\n\\nFPQ system is used for entry and reporting of quality data. It is national database for all quality\\nchecks. It is used to record field performance quality scores of resources and based on the entry\\nof it evaluate the quality scores. It is also used for score sheet and contractor management. Base\\non the score sheets auditors performs the transaction audits. FPQ also provides the transactional\\nand statistical reports.\\nV21 is crucial interface between the OSS and the network. It is based on Metasolv's component\\nOMS.\\nOMS: A Centralized Order Management system that allows changing processes and adding\\ninterfaces automatically\\n\\n\\u2022 Off Shore Project Manager for various integration projects for the client.\\n\\u2022 Requirement Understanding for future development and enhancement by interacting with\\nClient, E2E Solution Designers and other stake holders.\\n\\u2022 Prepared application performance improvement plan such CSIP (Continuous Service\\nImprovement Plan), Get-well Plan.\\n\\u2022 Providing estimation of effort and timescale for all the project deliveries\\n\\u2022 Managing components deliveries impacted by various Releases\\n\\u2022 Perform project planning, scheduling, monitoring, and reporting activities.\\n\\u2022 Interface with the client team to update them on the issues, risks and status of the offshore\\ndelivery.\\n\\u2022 Part of Application/Detail Design team to design high level and low level of the integration work.\\n\\u2022 Ensure system is delivered within planned cost, timescale and resource budgets.\\n\\u2022 Perform Release Management\\n\\u2022 Effort Estimation, Cost estimation, Allocate work to the team, track and raise the queries and\\nresolve issues related to deliveries.\\n\\u2022 Design, Development, Testing for various projects.\\n\\u2022 Change Requests/Maintenance Release\\n\\u2022 Resolving technical issues relating to application from offshore\\n\\u2022 Training &amp; Mentoring new resources for the Projects.\\n\\u2022 Oracle Database Migration, Application Migration to VDC environment.\\n\\u2022 Completed VDC Migration (DaaS, CaaS, MaaS) for various application\\n\\nAlong-side the responsibilities mentioned above I was involved in various initiatives by client for\\nimprovement in team efficiency like Six Sigma and Lean management that saved lots of efforts\\nand in turns monetary benefits to customer.\\n\\nWe also developed solutions to various issues which reduced incidents count that also reduce\\nturnaround time for resolution of the issue that engineer faced. For which we have received Blue\\nRibbon Award.\\n\\n\\n\\nTeam Lead\\n\\nBritish Telecomm UK -  UK -\\n\\nJune 2006 to July 2010\\n\\nEWMP-Tacticals contains Robotic systems formerly with the FastTrack solutions Team within BT.\\nRobotic systems were developed with the purpose of reducing the manual/ repetitive work done\\nby the Field engineers. This work is automated by Robots and User interface interacting with\\nvarious systems like CSS, Work Manager and other components. It is bunch of 16 applications\\n\\n\\u2022 Off Shore Project Manager for various integration projects for the client.\\n\\u2022 Requirement Understanding for future development and enhancement by interacting with\\nClient, E2E Solution Designers and other stake holders.\\n\\u2022 Prepared application performance improvement plan such CSIP (Continuous Service\\nImprovement Plan), GetWell Plan.\\n\\u2022 Providing estimation of effort and timescale for all the project deliveries\\n\\u2022 Managing components deliveries impacted by various Releases\\n\\u2022 Perform project planning, scheduling, monitoring, and reporting activities.\\n\\u2022 Interface with the client team to update them on the issues, risks and status of the offshore\\ndelivery.\\n\\u2022 Part of Application/Detail Design team to design high level and low level of the integration work.\\n\\u2022 Ensure system is delivered within planned cost, timescale and resource budgets.\\n\\u2022 Perform Release Management\\n\\u2022 Effort Estimation, Cost estimation, Allocate work to the team, track and raise the queries and\\nresolve issues related to deliveries.\\n\\u2022 Design, Development, Testing for various projects.\\n\\u2022 Change Requests/Maintenance Release\\n\\u2022 Resolving technical issues relating to application from offshore\\n\\u2022 Training &amp; Mentoring new resources for the Projects.\\n\\u2022 Oracle Database Migration, Application Migration to VDC environment.\\n\\u2022 Completed VDC Migration (DaaS, CaaS, MaaS) for various application before EOSL (End of life\\ncycle of the application)\\n\\nFor one of the legacy application (FastQ) , we have provided L3 support, application basically\\ndeveloped Oracle HTTPS based and Tomcat as Service to handle it.\\nDuring change in business level we have done development and changes for this application for\\nwhich Customer gives me Start Team player award as this was legacy application and before this\\nchange there was no change done for more than 6 years.\\n\\nSystem Analyst\\n\\nGE Countrywide, Lending and Repay Management -\\n\\nMay 2005 to April 2006\\n\\nLeasing functionality as per the standard defined by financial institution. It includes all the\\nfunctionality from Creation of Group, Company, and Creation of Trenches, Disbursing Loan\\nAgreement No. Capitalizing LAN.\\nIn Repayment Management System will take care of Installment receipt, Write-off cases, Charges\\nfor delinquent cases, Foreclosure of LAN etc\\n\\n\\n\\nThis application was developed from Scratch so involved in every part of application life cycle\\nfrom requirement gathering till UAT support before go-live\\n\\n\\u2022 Database design, GUI design.\\n\\u2022 Development of database objects like procedure packages, and development of GUI.\\n\\u2022 Design and developed customized report as per client requirement.\\n\\u2022 Component testing.\\n\\u2022 End to end test support.\\n\\u2022 UAT support and post deployment support.\\n\\nEDUCATION\\n\\nBachelor of Engineering in ELECTRONICS AND TELECOMMUNICATION\\n\\nAmravati University -  Amravati, Maharashtra\\n\\n1997 to 1999\\n\\nDiploma in INDUSTRIAL ELECTRONICS\\n\\nTechnical Board of Education Bombay -  Mumbai, Maharashtra\\n\\n1993 to 1996\\n\\nSKILLS\\n\\nMENTORING (10+ years), SCHEDULING (9 years), ORACLE (9 years), SOLUTIONS (9 years),\\nBENEFITS (4 years)\\n\\nADDITIONAL INFORMATION\\n\\nI.T KNOWLEDGE &amp; SKILLS\\nProgramming Languages: VB script, C, C++, Visual Basic, COM/DCOM\\nDatabases: Oracle, SQL,\\nDevelopment Tools: Toad, PL/SQL Developer, Crystal Report, Putty,Clarify, GSD, RTC, JIRA,\\nConfluence, VSS, PVCS,\\nWeb Servers: IIS, Oracle HTTP Server on Windows, Weblogic 10.3, WebSphere, Apache Tomcat,\\nMTS\\nBatch Scheduling: Control-M, Cron0Jobs, Windows Schedulers\\nOperating Systems: Windows [\\u2026] Pro &amp; Server/XP Home &amp; Professional/2003 Server/\\nVista/7 Pro &amp; Enterprise/8/10, MS-DOS, UNIX, Linux\\nWindows Packages: Microsoft Office: (Word, Excel, Access, Outlook and PowerPoint), Oracle\\nDBMS, Internet Explorer, Netscape, Lotus Notes, Adobe Flash, Photoshop, and CITRIX Metaframe\\n1.8/XP\\nTransferable Skills: Excellent business skills, project management, presentation, interpersonal,\\ncommunication and report writing skills, Team Mentoring\\n\\nOTHER SKILLS\\n\\u2022 Sound customer-facing skills: drive demos, status calls, issues &amp; escalation handling and\\nprovide solutions which benefits the business and customer\\n\\n\\n\\n\\u2022 Dynamic Team leader, strong resource management, team building skills and conflict\\nmanagement. Strong in result oriented service delivery to the customer\\n\\u2022 Excellent cross-vendor communication skills\\n\\u2022 Strong Analytical &amp; problem solving ability and proactively drive opportunities to resolution\\nwithout supervision\",\n          \"Jatin Arora\\nSDET Automation Engineer, Infosys - CRD (Capital Group of Companies)\\n\\nPehowa, Haryana - Email me on Indeed: indeed.com/r/Jatin-Arora/a124b9609f62fbcb\\n\\n3.6 years of experience in Automation Testing tools like Selenium (C#), Java, dot Net Technology\\nand other Testing tools like JIRA, QC. Proficient in testing on Client/Server and Web-based with\\ngood experience in creating the Test Plan and testing framework\\n\\n\\u2022 Experience in SQA including Selenium with data driven framework.\\n\\u2022 Experience in working on C# and dot net technologies.\\n\\u2022 Automated the Test data creation using Selenium as value added service for a client which is\\nbeing used by the client and bought 30% cost reduction in data setup.\\n\\u2022 Developed Test Case Generator as value added services for client which reduced time and cost\\nby\\n45% being spent on data creation and provide more productivity.\\n\\u2022 Developed an Infosys Go Safe Android App during participation in Global Hackathon\\n\\u2022 Excellent communications skills and able to liaise with key customer contacts and vendors to\\nresolve software issues.\\n\\u2022 Having excellent problem solving and analytical skills\\n\\nCompetencies Developed:\\n\\nSelenium WebDriver C# ADO.Net SQL HTML, CSS\\nJava Unix Quality Center Atlassian JIRA MTM\\nMicrosoft SQL Server Visual Studio Rapid SQL Toad Confluence\\nEclipse Visual Studio BitBucket NUnit MindMaps\\n\\nTesting Skills:\\nSDLC, STLC, Test Planning, Requirement Analysis, Agile Methodology, DevOps Methodology,\\nScrum, Waterfall, Software Quality, Defect Tracking, Regression Testing, System Testing\\n\\nWORK EXPERIENCE\\n\\nSDET Automation Engineer, Infosys\\n\\nCRD (Capital Group of Companies) -  Chandigarh, Chandigarh -\\n\\nFebruary 2017 to Present\\n\\nCRD (Charles River Development IMS automates the compliance workflow and provides\\ncentralized compliance monitoring and management. The highly scalable compliance engine\\nsupports very high volumes of trades, compliance rules, accounts and group of accounts.\\n\\n\\u2022 Design and implemented test scenarios, test cases, QA processes and procedures.\\n\\u2022 Automated and delivered high quality automation scripts using C#.\\n\\u2022 Writing SQL queries to validate data from database.\\n\\u2022 Used BitBucket for code repository.\\n\\u2022 Communication with stakeholder for business and functional requirements\\n\\nhttps://www.indeed.com/r/Jatin-Arora/a124b9609f62fbcb?isid=rex-download&ikw=download-top&co=IN\\n\\n\\n\\u2022 Perform requirements analysis and impact analysis for enhancements and changes\\n\\u2022 Creating weekly Test Unit creation and execution report\\n\\nInfosys Training, Test Engineer Trainee\\n\\nNext Generation Volume Licensing (Microsoft) -  Mysore, Karnataka -\\n\\nAugust 2014 to November 2014\\n\\nA detailed hands on training of C# and SQL concepts and testing training.\\n\\nTest Engineer, Infosys\\n\\nNext Generation Volume Licensing (Microsoft) -  Hyderabad, Telangana -\\n\\nApril 2014 to November 2014\\n\\nJan 2017\\n\\nProject Next Generation Volume Licensing (NGVL) is a strategic change initiative led by\\nWorld Wide Licensing &amp; Pricing (WWLP), Operations, MSIT, and Worldwide Operations in\\npartnership with EPG, SMS&amp;P, and WPG to transform the Volume Licensing business so that\\nit can scale for the next 20 years, compete more quickly in new markets, and deliver a superior\\nlicensing experience for our customers, partners, sellers, and operations personnel.\\n\\n\\u2022 Designed and implemented test scenarios, test cases, QA processes and procedures.\\n\\u2022 Automated and delivered high quality automation scripts with Selenium using C#.\\n\\u2022 Preparing SQLs for validating data in database.\\n\\u2022 Communicated with stakeholder for business and functional requirements\\n\\u2022 Performed requirement analysis and impact analysis for enhancements and changes\\n\\u2022 Logging and tracking defects and preparing backlog report\\n\\u2022 Created weekly Test Unit creation and execution report\\n\\u2022 Performed peer reviews and estimates which helped to automate 95% web site automation\\n\\nEDUCATION\\n\\nB.Sc in Computer Science\\n\\nKurukshetra University -  Kurukshetra, Haryana\\n\\nTagore Public School -  Pehowa, Haryana\",\n          \"Raktim Podder\\n6+ Exp in banking operations and credit assessment\\n\\nPune, Maharashtra - Email me on Indeed: indeed.com/r/Raktim-Podder/32472fc557546084\\n\\nWilling to relocate: Anywhere\\n\\nWORK EXPERIENCE\\n\\nSME\\n\\nTCS\\n\\nTata Consultancy Services: Project TELSTRA (AUSTRALIA)\\nSr Process Executive SME:\\nTelecom Business Case Management.\\nTechnical support to the onsite engineers.\\nDealers support function.\\nEmails regarding connection escalations.\\nTech implementations in telecom.\\nLooking after the day to day business production.\\nTeam management:\\nHandling a team of 18 FTE\\u2019s\\nDaily rostering\\nOne on one\\u2019s\\nPerformance management.\\nCommunicating process updates.\\nWFM\\nEOD reporting on team performance.\\nHuddles and catch-up\\u2019s\\nSystem access request for new joiners.\\nProviding training to new joiners.\\nConflict management.\\nBusiness performance reporting.\\nNetwork setup and network access management as per requirement.\\nTesting line and networking working capacity for minimal disruption.\\nSetting up wireless channels for customers.\\nProviding one stop solution for escalations from customers.\\nLooking over the B2B connection setup of customers.\\nException Management: Telstra Digital\\nCase management\\nOrder built\\nEscalations handling.\\n\\nCCSS Rep\\n\\nHSBC Electronic Data Processing India Pvt -  Bengaluru, Karnataka -\\n\\nAugust 2014 to November 2016\\n\\nhttps://www.indeed.com/r/Raktim-Podder/32472fc557546084?isid=rex-download&ikw=download-top&co=IN\\n\\n\\nHSBC: UK onboarding and KYC\\nCustomer Relationship Management and on boarding:\\nSetting up and checking KYC documents.\\nNational ID\\nAddress proofs\\nIncome proofs\\nAddition security for additional credits.\\nCredit scoring report from external credit rating agencies in UK.\\nCalling the customer and informing the current status of the process.\\nAsking for additional documentation if required.\\nInterviewing the customer for understanding his/her portfolio.\\nUploading documents and creating profile in BMM and sending for approval.\\nLiaising with branch and credit control for additional requirements and if needed execution of\\nthose requirements.\\nVolume of production or volume of documentation forecasting based on the current sales and\\nbranch production:\\nLiaising with branch to understand the volume.\\nLiaising with sales to under the targets and performance ratio to determine the incoming CRM\\nvolume.\\nDetermining if there is a dip in CRM production or rise based on:\\nVolume comparison and trend analysis reporting to the higher managements.\\nWeekly/ Monthly / Quarterly dashboard creation.\\nDaily volume trend analysis.\\nProduction and process reporting EOD.\\nTechnical Implementation support:\\nRequirements specifications to the development team to improve the applications in the project.\\nUAT user acceptance testing of new applications in the project and reporting the same to the\\nIT team\\nSit with development to understand the reason behind the implementation and communicating\\nthe same to the FTE\\u2019s\\nTraining provision on new applications to the FTE\\u2019s\\nChanges implementation if required to the development team.\\nOnline banking platform support:\\nHelping the online banking team to implement the CRM online.\\nUnderstanding the requirements of the management in regards to what they want and why they\\nwant to integrate the CRM into online banking.\\nMeeting setup to understand requirements.\\nOnce the requirements have been framed we sit with the development team to provide them\\nunderstanding of the CRM process and what is required by CRM that needs integration in the\\nonline banking platform.\\nProviding support in every stage of website coding development:\\nCommunicating the scope and purpose of the website to the development teams.\\nHelping with baseline setup.\\nProviding data to the development team:\\nWhat will be the content of the CRM tool in the website.\\nHow customers can access the tool online to complete their KYC.\\nIllustration of documents required will be on the page or not.\\nWhat kind of documents will be uploaded in the website.\\nWhat kind of files will the website support.\\n\\n\\n\\nWhere will it be stored after it gets uploaded.\\nWhere the files will be sent after it gets uploaded for approvals.\\nHow will the customer know of the status of the application process by automated email or by\\ntext or by both.\\nWhat other links will be there on the online CRM tool which can be useful for the customer.\\nWhat will the customer do if they are in confusion while uploading the documents for which a\\nweb chat can be introduced to provide support and direct contact with the executive.\\nUnderstanding the size of the project and what resources are required to execute the project.\\nUnderstanding the risk involved in executing the new codes in the running website:\\nWhen will the maintenance take place at what time and what date to avoid minimal customer\\nimpact.\\nInformation provision providing the customer with website maintenance information and non\\nusable timescale.\\nHow many FTE\\u2019s required from operations for UAT of a particular code so that manpower planning\\nis maintained and BAU is not effected.\\nAfter the above the estimation of the project starts:\\nEstimating the cost involved in this implementation\\nFTE requirements\\nMethodology used for development.\\nResources and technical knowhow required.\\nOnce the above function is performed the details of which is framed in a document template and\\nsent to the higher management for approval.\\nOnce the approval comes the development begins.\\nTracking and estimation support is given at steps where it is required.\\nAfter the implementation the UAT is again performed and asked for further requirements or if the\\nmanagement is happy with the implementation then the GO LIVE is arranged and executed.\\n\\nInfosys\\n\\nProcess Executive\\n\\n\\u2022 Infosys PVT LTD: National Australian Bank Project (Australian, Tasmania and New Zealand)\\n\\u25e6 Credit assessment executive for credit cards:\\n* Setting up credit memo for approval in SAP.\\n* Credit appraisal or credit assessment:\\n\\u2022 Preparation of financial data.\\n\\u25e6 Probability of default calculations.\\n\\u25e6 Credit risk ratio analysis.\\n\\u2022 Proposal preparation.\\n\\u2022 Assessment of proposal.\\n\\u2022 Sanction/approval of proposal by appropriate sanctioning authority.\\n\\u2022 Documentations, agreements, mortgages.\\n\\u2022 Disbursement of loan Post sanctions activities such as receiving stock statements.\\n\\u2022 Review of accounts, renew of accounts, etc (On regular basis) if CDD is required by the client.\\n\\u25e6 Credit Reporting and Analysis:\\n* Weekly monthly and quarterly report generation regarding performing and non performing\\nportfolios.\\n\\u2022 Solution design for non performing portfolios:\\n\\u25e6 Setting up project documents and requirements gathering from offshore branch officials to\\nunderstand the barriers and implementations expected from the project.\\n\\n\\n\\n\\u25e6 Casual meetings and client calls to understand the requirement and setting up targets or\\nvolumes of expected production.\\n\\u25e6 Once the requirements have been gathered a project plan is formed and the initiation is given\\nfor approval.\\n\\u25e6 Once the initiation have been approved a root cause analysis is performed to understand the\\ncurrent standings using tools like:\\n* 5 why's\\n* Brainstorming\\n* Decision matrix\\n* Pareto diagram\\n\\u25e6 Once the root cause is identified then as per the business need an elicitation of the business\\nproblem is defined and communicated.\\n\\u25e6 Project requirements and implementation:\\n* Communicating the current standing of the portfolio to the team and communicating the\\nrequirements.\\n* Documenting the current standing of the portfolio:\\n\\u2022 Historical credit loss report.\\n\\u2022 Pipeline reporting.\\n\\u2022 Collections dashboard.\\n* Once the communication is done the implementations in the projects starts:\\n\\u2022 We have understood using the root cause as to why the Credit Card is running at daily loss\\n\\u2022 We have understood using the data gathering what is the current standing of the credit card\\nportfolio.\\n\\u25e6 Using the above two determining what changes to be made in the process of collections.\\n\\u25e6 What recovery solutions can be provided to pool in the bad debts in the portfolio.\\n\\u25e6 Sitting with the sales team to ask them how to target the base.\\n\\u25e6 Sitting with credit assessment officers to introduce new techniques and models to forecast\\ncredit lending capacity of a customer.\\n* Once the implementations is completed we move on to the controlling of the project where we\\ndefine the improvements and analyse:\\n\\u2022 Present and Past performance analysis.\\n\\u2022 Trend Measurement of the portfolio:\\n\\u25e6 Bad Debt percentages.\\n\\u25e6 Loss increase or decrease percentage.\\n\\u2022 Percentage increase or decrease of the performing ratio using:\\n\\u25e6 Graphs\\n* Vertical\\n* Trending\\n* Hybrid\\n\\u25e6 Pie charts\\n\\u25e6 Scatter plots\\n\\u2022 Once the control setup has been initiated the process then goes into automation and the credit\\ncycle is completed until new requirements come.\\n\\nEDUCATION\\n\\nBcom\\n\\nWest Bengal State University\\n\\n\\n\\nSKILLS\\n\\nEDD, CDD, credit risk assessment, KYC, Banking, credit risk analysis, Customer Handling,\\nPortfolio Management, Customer Service\\n\\nAWARDS\\n\\nBest Quality\\n\\nJanuary 2011\\n\\nRising Star\\n\\nJune 2015\\n\\nBPS star performer\\n\\nJune 2016\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":4}],"source":["df = pd.DataFrame.from_dict(data).drop(columns=[\"extras\"])\n","df.sample(5)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"dLfVmRZqG-lg","executionInfo":{"status":"ok","timestamp":1731059576275,"user_tz":-180,"elapsed":4,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["df[\"annotation\"] = df[\"annotation\"].apply(lambda x: [i for i in x if len(i[\"label\"]) > 0 and i[\"label\"][0] != \"UNKNOWN\"])\n","\n","ents = list(df[\"annotation\"].apply(\n","    lambda x:\n","        [\n","            (np.nan if len(i[\"label\"]) == 0 else i[\"label\"][0]) for i in x\n","        ]\n",").explode().unique())\n","\n","#adding chunking\n","chunked_ents = [f'I_{ent}' for ent in ents] + [f'B_{ent}' for ent in ents] + ['O']\n","label2id = {k : i for i, k in enumerate(chunked_ents)}"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"iFO1Tu2RG-lg","executionInfo":{"status":"ok","timestamp":1731059576275,"user_tz":-180,"elapsed":3,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["from pprint import pprint\n","\n","def preprocess(txt):\n","    # pat = r'(?<!\\n)\\n'\n","    # pat = r'[?=\\n]\\n'\n","    n_pat = r\"\\n\"\n","    s_pat = r\" {2,10}\"\n","    # b_l_pat = r\"(?<=[^\\s])?(\\()(?=[^\\s])?\"\n","    # b_r_pat = r\"(?<=[^\\s])?(\\))(?=[^\\s])?\"\n","    # b_l_pat = r\"(?<=[^\\s])(\\()\"\n","    # b_r_pat = r\"(\\))(?=[^\\s])\"\n","    # txt = re.sub(b_l_pat, ' (', txt)\n","    # txt = re.sub(b_r_pat, ') ', txt)\n","    txt = re.sub(n_pat, ' ', txt)\n","    txt = re.sub(s_pat, ' ', txt)\n","    return txt\n","    # return txt"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y5HNVPNQG-lh","executionInfo":{"status":"ok","timestamp":1731059585509,"user_tz":-180,"elapsed":9237,"user":{"displayName":"ISY640","userId":"14578547707035782428"}},"outputId":"002c2b79-98d1-4f1d-b870-7830cda005c7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["from transformers import AutoModelForTokenClassification, AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"lakshyakh93/deberta_finetuned_pii\")\n","model = AutoModelForTokenClassification.from_pretrained(\"lakshyakh93/deberta_finetuned_pii\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndJVmwOPG-lh","executionInfo":{"status":"ok","timestamp":1731059585510,"user_tz":-180,"elapsed":8,"user":{"displayName":"ISY640","userId":"14578547707035782428"}},"outputId":"b0313d8c-5500-4c5f-8274-f6a80ecdc877"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["13.0"]},"metadata":{},"execution_count":8}],"source":["num_params = 0\n","for p in model.parameters():\n","    num_params += p.nelement()\n","num_params // 10e6"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"vLXVh_crG-li","executionInfo":{"status":"ok","timestamp":1731059585511,"user_tz":-180,"elapsed":5,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["def clean_labels(x):\n","    x = sorted(x, key = lambda x: x['points'][0]['start'])\n","    r = 0\n","    new_x = []\n","    for l in x:\n","        if r > l['points'][0]['start']: continue\n","        r = l['points'][0]['end']\n","        new_x.append(l)\n","\n","    return new_x\n","\n","df[\"annotation\"] = df[\"annotation\"].apply(clean_labels)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"AoJRjlx9G-li","executionInfo":{"status":"ok","timestamp":1731059096249,"user_tz":-180,"elapsed":5,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["# labels = df[\"annotation\"][0]\n","# txt = df[\"content\"][0]\n","\n","# input_ids = []\n","# new_labels = []\n","# last_r = 0\n","# for ent in labels:\n","\n","#     #getting plain text and entity text\n","#     o = preprocess(txt[last_r:ent[\"points\"][0]['start']])\n","#     ent_txt = preprocess(ent[\"points\"][0][\"text\"])\n","\n","#     #updating right border\n","#     last_r = ent[\"points\"][0]['end'] + 1\n","\n","#     # getting labels ids\n","#     label = ent[\"label\"][0]\n","#     b_label_id = label2id[f'B_{label}']\n","#     i_label_id = label2id[f'I_{label}']\n","#     o_label_id = label2id[\"O\"]\n","\n","#     #tokenizing plain text\n","#     if len(o.strip()) != 0:\n","#         o_tokens = tokenizer(o, add_special_tokens=False)[\"input_ids\"]\n","#         input_ids.extend(o_tokens)\n","#         new_labels.extend([o_label_id] * len(o_tokens))\n","\n","#     #by space tokenization\n","#     ent_txt_words = ent_txt.split(\" \")\n","#     b_ent = ent_txt[0]\n","#     i_ent = ent_txt[1:]\n","\n","#     #tokenizing beggining of entity\n","#     b_ent_tokens = tokenizer(b_ent, add_special_tokens=False)[\"input_ids\"]\n","#     input_ids.extend(b_ent_tokens)\n","#     new_labels.extend([b_label_id] * len(b_ent_tokens))\n","\n","#     #tokenizing inner part of entity\n","#     i_ent_tokens = tokenizer(i_ent, add_special_tokens=False)[\"input_ids\"]\n","#     input_ids.extend(i_ent_tokens)\n","#     new_labels.extend([i_label_id] * len(i_ent_tokens))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Xp76O17RG-li","executionInfo":{"status":"ok","timestamp":1731059675090,"user_tz":-180,"elapsed":291,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["class NERDataset(Dataset):\n","    def __init__(\n","            self,\n","            texts,\n","            labels_lists,\n","            tokenizer,\n","            max_len=512\n","        ):\n","        self.labels = labels_lists\n","        self.texts = texts\n","        self.tokenizer = tokenizer\n","        self.max_len=max_len\n","\n","    def __getitem__(self, idx):\n","        txt = self.texts[idx]\n","        labels = self.labels[idx]\n","\n","        input_ids = []\n","        new_labels = []\n","        last_r = 0\n","        for ent in labels:\n","\n","            #getting plain text and entity text\n","            o = preprocess(txt[last_r:ent[\"points\"][0]['start']])\n","            ent_txt = preprocess(ent[\"points\"][0][\"text\"])\n","\n","            #updating right border\n","            last_r = ent[\"points\"][0]['end'] + 1\n","\n","            # getting labels ids\n","            label = ent[\"label\"][0]\n","            b_label_id = label2id[f'B_{label}']\n","            i_label_id = label2id[f'I_{label}']\n","            o_label_id = label2id[\"O\"]\n","\n","            #tokenizing plain text\n","            if len(o.strip()) != 0:\n","                o_tokens = tokenizer(o, add_special_tokens=False)[\"input_ids\"]\n","                input_ids.extend(o_tokens)\n","                new_labels.extend([o_label_id] * len(o_tokens))\n","\n","            #by space tokenization\n","            ent_txt_words = ent_txt.split(\" \")\n","            b_ent = ent_txt_words[0]\n","            i_ent = ent_txt_words[1:]\n","\n","            #tokenizing beggining of entity\n","            b_ent_tokens = tokenizer(b_ent, add_special_tokens=False)[\"input_ids\"]\n","            input_ids.extend(b_ent_tokens)\n","            new_labels.extend([b_label_id] * len(b_ent_tokens))\n","\n","            #tokenizing inner part of entity\n","            i_ent_tokens = tokenizer(i_ent, is_split_into_words=True, add_special_tokens=False)[\"input_ids\"]\n","            input_ids.extend(i_ent_tokens)\n","            new_labels.extend([i_label_id] * len(i_ent_tokens))\n","\n","        #Truncating\n","        input_ids = input_ids[:self.max_len - 2]\n","        new_labels = new_labels[:self.max_len - 2]\n","\n","        #adding special tokens_ids CLS ->\n","        input_ids = [1] + input_ids + [2]\n","        new_labels = [0] + new_labels + [0]\n","\n","        #adding paddings and attention mask\n","        input_ids = input_ids + [0] * (self.max_len - len(input_ids))\n","        new_labels = new_labels + [0] * (self.max_len - len(new_labels))\n","        attention_mask = [1] * (len(new_labels)) + [0] * (self.max_len - len(new_labels))\n","\n","        return {\n","            \"input_ids\" : torch.tensor(input_ids, dtype=torch.long),\n","            \"labels\" : torch.tensor(new_labels, dtype=torch.float),\n","            \"attention_mask\" : torch.tensor(attention_mask, dtype=torch.long)\n","        }\n","\n","    def __len__(self, ):\n","        return len(self.texts)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"fDpUjXeQG-lj","executionInfo":{"status":"ok","timestamp":1731059679485,"user_tz":-180,"elapsed":2574,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train, val = train_test_split(df, test_size=0.2, random_state=SEED)\n","\n","train, val = train.reset_index(drop=True), val.reset_index(drop=True)\n","\n","train_ds = NERDataset(train[\"content\"], train[\"annotation\"], tokenizer=tokenizer, max_len=512)\n","val_ds = NERDataset(val[\"content\"], val[\"annotation\"], tokenizer=tokenizer, max_len=512)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"XENmMwQlG-lj","executionInfo":{"status":"ok","timestamp":1731059098429,"user_tz":-180,"elapsed":5,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["# Setting model for finetuning\n","\n","model.classifier = nn.Linear(768, len(label2id.keys()))"]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NF6IRBtNKyNH","executionInfo":{"status":"ok","timestamp":1731059200080,"user_tz":-180,"elapsed":5,"user":{"displayName":"ISY640","userId":"14578547707035782428"}},"outputId":"bf3b962d-4e5c-491d-9524-6d3af892a950"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DebertaForTokenClassification(\n","  (deberta): DebertaModel(\n","    (embeddings): DebertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n","      (LayerNorm): DebertaLayerNorm()\n","      (dropout): StableDropout()\n","    )\n","    (encoder): DebertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x DebertaLayer(\n","          (attention): DebertaAttention(\n","            (self): DisentangledSelfAttention(\n","              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n","              (pos_dropout): StableDropout()\n","              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n","              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): DebertaLayerNorm()\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): DebertaLayerNorm()\n","            (dropout): StableDropout()\n","          )\n","        )\n","      )\n","      (rel_embeddings): Embedding(1024, 768)\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=21, bias=True)\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","execution_count":14,"metadata":{"id":"gx0ySXy8G-lj","executionInfo":{"status":"ok","timestamp":1731059800839,"user_tz":-180,"elapsed":268,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["class NERworker:\n","\n","    def __init__(self, device):\n","        self.device = device\n","        if (torch.cuda.is_available()):\n","          print(torch.cuda.get_device_name(0))\n","\n","    def init_loaders(self, train, test, batch_size=16):\n","\n","        self.train_loader = DataLoader(\n","            train,\n","            batch_size=batch_size,\n","            shuffle=True,\n","            # num_workers=0,\n","            # pin_memory=True\n","        )\n","        self.test_loader = DataLoader(\n","            test,\n","            batch_size=batch_size,\n","            shuffle=False,\n","            # num_workers=0,\n","            # pin_memory=True\n","        )\n","\n","    def init_model(self, model):\n","        model.eval()\n","        self.model = model.to(self.device)\n","\n","    def train_one_epoch(self):\n","\n","        self.model.train()\n","        stream = tqdm(self.train_loader)\n","        self.lossi_train = []\n","        self.mean_loss_train = []\n","\n","        for batch in stream:\n","            # batch = {k : i.to(self.device) for k, i in batch.items()}\n","            # out = self.model(\n","            #     input_ids = batch[\"input_ids\"],\n","            #     attention_mask = batch[\"attention_mask\"]\n","            # ).logits\n","            # print(batch[\"labels\"].shape)\n","            # print(out.shape)\n","            # loss = nn.functional.cross_entropy(out, batch[\"labels\"].view(len(batch[\"attention_mask\"]), -1, 1))\n","            # self.lossi_train.append(loss.item())\n","\n","            # self.optimizer.zero_grad()\n","            # loss.backward()\n","            # self.optimizer.step()\n","\n","            # stream.set_prefix(train_loss=np.mean(self.lossi_train))\n","\n","            # self.mean_loss_train.append(np.mean(self.lossi_train))\n","            pass\n","\n","    @torch.no_grad()\n","    def eval_one_epoch(self):\n","\n","        self.model.eval()\n","\n","        stream = tqdm(self.test_loader)\n","\n","        self.lossi_val = []\n","        self.mean_loss_val = []\n","\n","        for batch in stream:\n","\n","            batch = {k : i.to(self.device) for k, i in batch.items()}\n","\n","            out = self.model(\n","                input_ids = batch[\"input_ids\"],\n","                attention_mask = batch[\"attention_mask\"]\n","            ).logits\n","\n","            loss = nn.functional.cross_entropy(out, batch[\"labels\"])\n","            self.lossi_val.append(loss.item())\n","\n","            stream.set_prefix(eval_loss=np.mean(self.lossi_val))\n","\n","            self.mean_loss_val.append(np.mean(self.lossi_val))\n","\n","        return np.mean(self.lossi_val)\n","\n","\n","\n","    def train(self, num_epochs, optimizer_name, lr):\n","\n","        self.optimizer = getattr(torch.optim, optimizer_name)(self.model.parameters(), lr)\n","\n","        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, factor=0.9, patience=5)\n","\n","        for epoch in range(1, num_epochs + 1):\n","\n","            print(\"EPOCH: \", epoch)\n","\n","            self.train_one_epoch()\n","            val_loss = self.eval_one_epoch()\n","\n","            scheduler.step(val_loss)\n","\n","\n","\n","worker = NERworker(device=torch.device(\"cpu\"))\n","worker.init_loaders(train_ds, val_ds, batch_size=4)\n","worker.init_model(model)"]},{"cell_type":"code","source":["for batch in worker.train_loader:\n","  pass"],"metadata":{"id":"ghcuEApBMo2d","executionInfo":{"status":"ok","timestamp":1731059807957,"user_tz":-180,"elapsed":3896,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"nC63brCBG-lk","executionInfo":{"status":"error","timestamp":1731059819988,"user_tz":-180,"elapsed":12033,"user":{"displayName":"ISY640","userId":"14578547707035782428"}},"outputId":"33ea227a-4670-47bd-f81d-4ab4594a6d5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH:  1\n"]},{"output_type":"stream","name":"stderr","text":["100%|| 44/44 [00:02<00:00, 18.75it/s]\n","  0%|          | 0/11 [00:05<?, ?it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-7690f91adf5c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1/0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m worker.train(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-3b89b546aaf4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs, optimizer_name, lr)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-3b89b546aaf4>\u001b[0m in \u001b[0;36meval_one_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             out = self.model(\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m         outputs = self.deberta(\n\u001b[0m\u001b[1;32m   1300\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    458\u001b[0m                 )\n\u001b[1;32m    459\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m                 hidden_states = layer_module(\n\u001b[0m\u001b[1;32m    461\u001b[0m                     \u001b[0mnext_kv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     ):\n\u001b[0;32m--> 373\u001b[0;31m         attention_output = self.attention(\n\u001b[0m\u001b[1;32m    374\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_states\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 1/0\n","torch.cuda.empty_cache()\n","worker.train(\n","    num_epochs=10,\n","    optimizer_name=\"Adam\",\n","    lr=3e-3,\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"kmsYLED0G-lk","executionInfo":{"status":"ok","timestamp":1731059384850,"user_tz":-180,"elapsed":261,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["del worker"]},{"cell_type":"code","source":["import gc\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlt77E1sLf97","executionInfo":{"status":"ok","timestamp":1731059400430,"user_tz":-180,"elapsed":270,"user":{"displayName":"ISY640","userId":"14578547707035782428"}},"outputId":"3cf47697-a8bf-4cd1-955f-9353d97ce1fc"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["294"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["n_params\n","model.()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":263},"id":"UOlZySngLjqp","executionInfo":{"status":"error","timestamp":1731059435227,"user_tz":-180,"elapsed":10,"user":{"displayName":"ISY640","userId":"14578547707035782428"}},"outputId":"a306d691-179d-4d73-da24-361b58f308ed"},"execution_count":19,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'DebertaForTokenClassification' object has no attribute 'size'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-18092846c96c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'DebertaForTokenClassification' object has no attribute 'size'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pi11UAjBLsA_"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}