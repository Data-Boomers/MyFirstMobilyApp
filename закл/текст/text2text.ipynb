{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPS4W4noHKetGt6Y99ywXGG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install -U sentence-transformers -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_s1DMMkLYntn","executionInfo":{"status":"ok","timestamp":1731331747328,"user_tz":-180,"elapsed":8589,"user":{"displayName":"ISY640","userId":"14578547707035782428"}},"outputId":"c9f4dbeb-3c3d-49fa-b833-bfde4b754ce8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/268.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m266.2/268.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.7/268.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"D03ureNmYh1k","executionInfo":{"status":"ok","timestamp":1731331795660,"user_tz":-180,"elapsed":449,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from sentence_transformers import SentenceTransformer\n","from transformers import AutoTokenizer, AutoModel"]},{"cell_type":"code","source":["model_name = 'cointegrated/rubert-tiny2'\n","\n","text_pairs = [\n","    (\"Какой сегодня день?\", \"Сегодня понедельник.\"),\n","    (\"Что такое машинное обучение?\", \"Машинное обучение — это область искусственного интеллекта.\"),\n","    (\"Как приготовить борщ?\", \"Для приготовления борща нужны свекла, капуста и мясо.\"),\n","    (\"Кто написал 'Войну и мир'?\", \"Роман 'Война и мир' написал Лев Толстой.\"),\n","    (\"Что такое квантовая механика?\", \"Квантовая механика изучает поведение микрочастиц.\"),\n","]\n","\n","queries = [p[0] for p in text_pairs]\n","answers = [p[1] for p in text_pairs]\n","\n","sen_model = SentenceTransformer(model_name, device=torch.device('cuda:0'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"820-e3ttZAiU","executionInfo":{"status":"ok","timestamp":1731332124984,"user_tz":-180,"elapsed":1615,"user":{"displayName":"ISY640","userId":"14578547707035782428"}},"outputId":"01a14e71-d04c-48e8-cae0-bfb24124c215"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["embeddings_queries = sen_model.encode(queries)\n","embeddings_answers = sen_model.encode(answers)"],"metadata":{"id":"C97T3C0eZNQ8","executionInfo":{"status":"ok","timestamp":1731332126230,"user_tz":-180,"elapsed":1250,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["sims = embeddings_queries @ embeddings_answers.T"],"metadata":{"id":"vcXavKmzboYJ","executionInfo":{"status":"ok","timestamp":1731332129243,"user_tz":-180,"elapsed":385,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["### Ручками"],"metadata":{"id":"sb--MmzBam_n"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n","model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")"],"metadata":{"id":"yplknsZ-bLDo","executionInfo":{"status":"ok","timestamp":1731332131636,"user_tz":-180,"elapsed":922,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def embed_bert_cls(text, model, tokenizer):\n","    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n","    with torch.no_grad():\n","        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n","    embeddings = model_output.last_hidden_state[:, 0, :]\n","    embeddings = torch.nn.functional.normalize(embeddings)\n","    return embeddings.cpu().numpy()"],"metadata":{"id":"LwiHXyATaKPt","executionInfo":{"status":"ok","timestamp":1731332131636,"user_tz":-180,"elapsed":3,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["embeddings_queries = embed_bert_cls(queries, model, tokenizer)\n","embeddings_answers = embed_bert_cls(answers, model, tokenizer)"],"metadata":{"id":"rtsBv20qazM4","executionInfo":{"status":"ok","timestamp":1731332132684,"user_tz":-180,"elapsed":4,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["sims = embeddings_queries @ embeddings_answers.T"],"metadata":{"id":"o92FUiWIbdWI","executionInfo":{"status":"ok","timestamp":1731332132684,"user_tz":-180,"elapsed":3,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["### getting scores"],"metadata":{"id":"w0PE3lVYb98P"}},{"cell_type":"code","source":["#default labels (max scored)\n","def get_best(sims, qs, ans):\n","  best_match = np.argmax(sims, axis=-1)\n","  preds = {qs[i] : ans[best_match[i]] for i in range(len(best_match))}\n","  return preds\n","\n","#get k best\n","k = 2\n","def get_k_best(k, sims, qs, ans):\n","  best_matches = np.argsort(sims, axis=-1, )\n","  preds = {qs[i] : np.array(ans)[best_matches[i][:-(k+1)]] for i in range(len(best_matches))}\n","  return preds"],"metadata":{"id":"Yqytk59scCpJ","executionInfo":{"status":"ok","timestamp":1731332729052,"user_tz":-180,"elapsed":520,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["preds = get_best(sims, queries, answers)\n","preds = get_k_best(2, sims, queries, answers)"],"metadata":{"id":"cliK-RfLcj42","executionInfo":{"status":"ok","timestamp":1731332779136,"user_tz":-180,"elapsed":532,"user":{"displayName":"ISY640","userId":"14578547707035782428"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LGMqy7r8ebdM"},"execution_count":null,"outputs":[]}]}