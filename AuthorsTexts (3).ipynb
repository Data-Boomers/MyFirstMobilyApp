{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T07:01:57.990774Z",
     "start_time": "2024-11-14T07:01:57.986317Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T21:02:25.949056Z",
     "start_time": "2024-11-13T21:02:25.388798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pip install transformers sentencepiece\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "\n",
    "\n",
    "# model.cuda()  # uncomment it if you have a GPU\n",
    "\n",
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].cpu().numpy()\n",
    "\n",
    "\n",
    "print(embed_bert_cls('привет друзья', model, tokenizer).shape)\n",
    "# (312,)\n"
   ],
   "id": "7f2c79a1a77b0883",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(312,)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:02:12.956785Z",
     "start_time": "2024-11-14T07:02:12.953755Z"
    }
   },
   "cell_type": "code",
   "source": "label_encoder = LabelEncoder()",
   "id": "e9763e3fc2061de8",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:02:19.395933Z",
     "start_time": "2024-11-14T07:02:16.236522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv('train_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "val_df = pd.read_csv('val_data.csv')"
   ],
   "id": "41c56e0fa7ebd2b9",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:02:19.410464Z",
     "start_time": "2024-11-14T07:02:19.400557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = train_df.rename({'writer': 'label'}, axis=1).drop('book', axis=1)\n",
    "test_df = test_df.rename({'writer': 'label'}, axis=1).drop('book', axis=1)\n",
    "val_df = val_df.rename({'writer': 'label'}, axis=1).drop('book', axis=1)"
   ],
   "id": "bdaafbb853886463",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:02:28.410943Z",
     "start_time": "2024-11-14T07:02:28.399119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df['label'] = label_encoder.fit_transform(train_df['label'])\n",
    "test_df['label'] = label_encoder.fit_transform(test_df['label'])\n",
    "val_df['label'] = label_encoder.fit_transform(val_df['label'])"
   ],
   "id": "36b455cde5675023",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:05:41.710845Z",
     "start_time": "2024-11-14T07:05:41.694952Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.info()",
   "id": "d3ffc4b6328b874c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46915 entries, 0 to 46914\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   46915 non-null  int64 \n",
      " 1   text    46915 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 733.2+ KB\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:05:43.641925Z",
     "start_time": "2024-11-14T07:05:43.637750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import DatasetDict, Dataset, load_dataset"
   ],
   "id": "c9c167e8a3a1f8c9",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:05:44.470488Z",
     "start_time": "2024-11-14T07:05:44.409873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка токенайзера и модели\n",
    "model_name = \"cointegrated/rubert-tiny\"\n",
    "# model_name = \"google-bert/bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "id": "db96e2479391ad99",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:21:15.578569Z",
     "start_time": "2024-11-14T07:21:15.426745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создание датасета из DataFrame\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ],
   "id": "3aa86db64cd4f315",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T21:08:49.281444Z",
     "start_time": "2024-11-13T21:08:49.276111Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset.",
   "id": "4ee6c0cbf54b3511",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['writer', 'book', 'text']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:22:56.514091Z",
     "start_time": "2024-11-14T07:22:56.511073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создание объекта DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ],
   "id": "43896ce225fc294e",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:05:50.644252Z",
     "start_time": "2024-11-14T07:05:50.639528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Функция предобработки данных\n",
    "def preprocess_function(examples):\n",
    "    tokenized_data = tokenizer(examples['text'], truncation=True, padding=True, max_length=128)\n",
    "    return tokenized_data"
   ],
   "id": "53e49bf7046a0cc3",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:24:11.174408Z",
     "start_time": "2024-11-14T07:23:00.018103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Токенизация данных\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ],
   "id": "6e741d15b72546e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/46915 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d06c343cbf81441db07386cd8c7b6340"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/9119 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "482d9f925a1449258cdcf83c51a073fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/9118 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa0003f6af9b4bd6a9d1d4ef0133ec45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:06:52.370594Z",
     "start_time": "2024-11-14T07:06:52.366403Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_datasets",
   "id": "f90436e5e4be3437",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 46915\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T21:04:40.674689Z",
     "start_time": "2024-11-13T21:04:40.667162Z"
    }
   },
   "cell_type": "code",
   "source": "train_df['writer'].value_counts()",
   "id": "7e7f67242b84b9fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "writer\n",
       "Dostoevsky           3157\n",
       "Fray                 2677\n",
       "Sergeev-Thsenskiy    2553\n",
       "Solzhenitsin         2422\n",
       "Kazantsev            2156\n",
       "Prishvin             2042\n",
       "Paustovskiy          1956\n",
       "Tolstoy              1926\n",
       "Leskov               1906\n",
       "Chekhov              1829\n",
       "Kataev               1705\n",
       "Turgenev             1591\n",
       "Ostrovsky            1568\n",
       "Gorky                1504\n",
       "Belyaev              1286\n",
       "Kuprin               1111\n",
       "Grin                 1104\n",
       "Averchenko           1068\n",
       "Pikul                1019\n",
       "Saltykov-schedrin     986\n",
       "Bunin                 927\n",
       "Fadeev                908\n",
       "Pelevin               888\n",
       "Ilf_petrov            858\n",
       "Serafimovich          855\n",
       "Zoschenko             837\n",
       "Gogol                 780\n",
       "Akunin                734\n",
       "Struhgatskie          692\n",
       "Gaydar                556\n",
       "Goncharov             457\n",
       "Dovlatov              442\n",
       "Pasternak             439\n",
       "Bulgakov              428\n",
       "Lukyanenko            412\n",
       "Shukshin              410\n",
       "Furmanov              402\n",
       "Pushkin               324\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:07:03.226706Z",
     "start_time": "2024-11-14T07:07:02.930372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка модели\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=38)"
   ],
   "id": "6450d0d17820f145",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:07:05.120031Z",
     "start_time": "2024-11-14T07:07:05.114237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Параметры обучения\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    # label_names=['labels'],\n",
    ")\n"
   ],
   "id": "6303947980138f35",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:07:07.629880Z",
     "start_time": "2024-11-14T07:07:07.244948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Определение Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    ")\n"
   ],
   "id": "75f6bfe4f7da56b4",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:19:43.323102Z",
     "start_time": "2024-11-14T07:07:08.189236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Запуск обучения\n",
    "trainer.train()"
   ],
   "id": "db67d0179fea3e21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17595' max='17595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17595/17595 12:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.587300</td>\n",
       "      <td>2.909965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.209400</td>\n",
       "      <td>2.721918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.040400</td>\n",
       "      <td>2.671815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17595, training_loss=2.4475792770190616, metrics={'train_runtime': 754.921, 'train_samples_per_second': 186.437, 'train_steps_per_second': 23.307, 'total_flos': 260688672668160.0, 'train_loss': 2.4475792770190616, 'epoch': 3.0})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:24:40.935650Z",
     "start_time": "2024-11-14T07:24:20.204551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "test_dataset = tokenized_datasets['test']\n",
    "\n",
    "# Используем метод predict для предсказания на тестовых данных\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n"
   ],
   "id": "c7d899e0765bcae6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:28:03.071236Z",
     "start_time": "2024-11-14T07:28:03.067513Z"
    }
   },
   "cell_type": "code",
   "source": "test_dataset",
   "id": "e86e6a201a739a9a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 9118\n",
       "})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:25:06.672109Z",
     "start_time": "2024-11-14T07:25:06.667854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Получение предсказанных классов (если это задача классификации)\n",
    "predicted_labels = predictions.predictions.argmax(axis=1)\n",
    "predicted_labels\n"
   ],
   "id": "c751e5965b0d23e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 18, 35, ..., 24, 30, 14])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:27:22.524156Z",
     "start_time": "2024-11-14T07:27:22.521479Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.metrics import accuracy_score, f1_score\n",
   "id": "2d00f9892dda1878",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:28:38.895617Z",
     "start_time": "2024-11-14T07:28:38.886804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy = accuracy_score(test_dataset['label'], predicted_labels)\n",
    "\n",
    "print(f'Точность модели: {accuracy}')"
   ],
   "id": "68a25f435a446775",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели: 0.2779118227681509\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:28:40.521762Z",
     "start_time": "2024-11-14T07:28:40.509441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "f1 = f1_score(test_dataset['label'], predicted_labels, average='macro')\n",
    "print(f'F1 модели: {f1}')"
   ],
   "id": "3e3a480a576bdfd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели: 0.173322047362297\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # Если вам нужно также сохранить оценки вероятностей\n",
    "# predicted_probabilities = predictions.predictions"
   ],
   "id": "ca7b81c3493614db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "de1072f0f78bb831"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T07:22:07.313871Z",
     "start_time": "2024-11-14T07:22:07.167961Z"
    }
   },
   "cell_type": "code",
   "source": "predictions = trainer.predict(test_dataset['text'])",
   "id": "c9b9179a2140c34f",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "vars() argument must have __dict__ attribute",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[76], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.11/site-packages/transformers/trainer.py:3946\u001B[0m, in \u001B[0;36mTrainer.predict\u001B[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3943\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m   3945\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[0;32m-> 3946\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3947\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPrediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\n\u001B[1;32m   3948\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3949\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[1;32m   3950\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.11/site-packages/transformers/trainer.py:4051\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   4048\u001B[0m observed_num_examples \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   4050\u001B[0m \u001B[38;5;66;03m# Main evaluation loop\u001B[39;00m\n\u001B[0;32m-> 4051\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   4052\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Update the observed num examples\u001B[39;49;00m\n\u001B[1;32m   4053\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobserved_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfind_batch_size\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4054\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobserved_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.11/site-packages/accelerate/data_loader.py:550\u001B[0m, in \u001B[0;36mDataLoaderShard.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    548\u001B[0m \u001B[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001B[39;00m\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 550\u001B[0m     current_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(dataloader_iter)\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[1;32m    707\u001B[0m ):\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:55\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.11/site-packages/transformers/trainer_utils.py:843\u001B[0m, in \u001B[0;36mRemoveColumnsCollator.__call__\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m    841\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, features: List[\u001B[38;5;28mdict\u001B[39m]):\n\u001B[1;32m    842\u001B[0m     features \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_remove_columns(feature) \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m features]\n\u001B[0;32m--> 843\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_collator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.11/site-packages/transformers/data/data_collator.py:92\u001B[0m, in \u001B[0;36mdefault_data_collator\u001B[0;34m(features, return_tensors)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;66;03m# In this function we'll make the assumption that all `features` in the batch\u001B[39;00m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;66;03m# have the same attributes.\u001B[39;00m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;66;03m# So we will look at the first element as a proxy for what attributes exist\u001B[39;00m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;66;03m# on the whole batch.\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_tensors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 92\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch_default_data_collator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m return_tensors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf_default_data_collator(features)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.11/site-packages/transformers/data/data_collator.py:131\u001B[0m, in \u001B[0;36mtorch_default_data_collator\u001B[0;34m(features)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(features[\u001B[38;5;241m0\u001B[39m], Mapping):\n\u001B[0;32m--> 131\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mvars\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    132\u001B[0m first \u001B[38;5;241m=\u001B[39m features[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    133\u001B[0m batch \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.11/site-packages/transformers/data/data_collator.py:131\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(features[\u001B[38;5;241m0\u001B[39m], Mapping):\n\u001B[0;32m--> 131\u001B[0m     features \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mvars\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m features]\n\u001B[1;32m    132\u001B[0m first \u001B[38;5;241m=\u001B[39m features[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    133\u001B[0m batch \u001B[38;5;241m=\u001B[39m {}\n",
      "\u001B[0;31mTypeError\u001B[0m: vars() argument must have __dict__ attribute"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Сохранение модели\n",
    "trainer.save_model(\"./rubert-tiny-finetuned\")"
   ],
   "id": "86e2abe7c93f8715"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
